{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Muffin vs Chihuahua — SOTA Classification Pipeline\n",
        "**Architecture**: EVA-02-Large + Swin-V2-Base + ConvNeXt-Base Hybrid Ensemble\n",
        "\n",
        "**Techniques**: SAM Optimizer | EMA | CutMix/Mixup | 5-Fold CV | Consensus Pseudo-Labeling | AMP | 12-Pass TTA\n",
        "\n",
        "**References**: Google Research (SAM), Meta (EVA-02, DINOv2), NVIDIA (Training Best Practices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1 — Imports & Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Import] timm 1.0.25\n",
            "[Device] Apple MPS\n",
            "[Data] TRAIN    : ./data/train (exists=True)\n",
            "[Data] TEST     : ./data/kaggle_test_final  (exists=True)\n",
            "[Data] PREV_SUB : ./data/test_solution_01.csv  (exists=True)\n",
            "[Data] CKPT     : ./checkpoints\n",
            "[Config] Architectures : ['swin_v2_b', 'convnext_base', 'eva02_large']\n",
            "[Config] Ensemble size : 15 base models\n"
          ]
        }
      ],
      "source": [
        "import ssl\n",
        "ssl._create_default_https_context = ssl._create_unverified_context\n",
        "\n",
        "import os\n",
        "import gc\n",
        "import json\n",
        "import copy\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.amp import autocast, GradScaler\n",
        "from torchvision import transforms, datasets, models\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "try:\n",
        "    import timm\n",
        "    TIMM_AVAILABLE = True\n",
        "    print(f\"[Import] timm {timm.__version__}\")\n",
        "except ImportError:\n",
        "    TIMM_AVAILABLE = False\n",
        "    print(\"[Import] timm not available — EVA-02 will be skipped\")\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "#  Reproducibility\n",
        "# ---------------------------------------------------------------------------\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "#  Device\n",
        "# ---------------------------------------------------------------------------\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    AMP_ENABLED, PIN_MEMORY = True, True\n",
        "    print(f\"[Device] CUDA — {torch.cuda.get_device_name(0)}\")\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = torch.device(\"mps\")\n",
        "    AMP_ENABLED, PIN_MEMORY = False, False\n",
        "    print(\"[Device] Apple MPS\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    AMP_ENABLED, PIN_MEMORY = False, False\n",
        "    print(\"[Device] CPU\")\n",
        "\n",
        "AMP_DTYPE = \"cuda\" if AMP_ENABLED else \"cpu\"\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "#  Data Paths (Local only)\n",
        "# ---------------------------------------------------------------------------\n",
        "BASE_DIR  = \"./data\"\n",
        "TRAIN_DIR = os.path.join(BASE_DIR, \"train\")\n",
        "TEST_DIR  = os.path.join(BASE_DIR, \"kaggle_test_final\")\n",
        "PREV_SUB  = os.path.join(BASE_DIR, \"test_solution_01.csv\")  # Previous submission (0.96315)\n",
        "CKPT_DIR  = \"./checkpoints\"\n",
        "os.makedirs(CKPT_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"[Data] TRAIN    : {TRAIN_DIR} (exists={os.path.exists(TRAIN_DIR)})\")\n",
        "print(f\"[Data] TEST     : {TEST_DIR}  (exists={os.path.exists(TEST_DIR)})\")\n",
        "print(f\"[Data] PREV_SUB : {PREV_SUB}  (exists={os.path.exists(PREV_SUB)})\")\n",
        "print(f\"[Data] CKPT     : {CKPT_DIR}\")\n",
        "\n",
        "if not os.path.exists(TRAIN_DIR):\n",
        "    raise FileNotFoundError(f\"Training data not found at {TRAIN_DIR}\")\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "#  Hyperparameters\n",
        "# ---------------------------------------------------------------------------\n",
        "IMG_SIZE         = 384\n",
        "BATCH_SIZE       = 8\n",
        "GRAD_ACCUM       = 4         # Effective batch = 32\n",
        "P1_EPOCHS        = 5         # Phase 1: Head-only warmup\n",
        "P2_EPOCHS        = 30        # Phase 2: Full SAM fine-tune\n",
        "P1_LR            = 1e-3\n",
        "P2_LR            = 5e-5\n",
        "WEIGHT_DECAY     = 0.05\n",
        "LABEL_SMOOTHING  = 0.1\n",
        "MIXUP_ALPHA      = 0.2\n",
        "CUTMIX_ALPHA     = 1.0\n",
        "MIX_PROB         = 0.5\n",
        "GRAD_CLIP        = 1.0\n",
        "PATIENCE         = 8\n",
        "N_FOLDS          = 5\n",
        "NUM_WORKERS      = 0         # macOS — set to 2+ on Linux\n",
        "SAM_RHO          = 0.05\n",
        "PSEUDO_THRESHOLD = 0.98      # Minimum confidence for pseudo-labeling\n",
        "EMA_DECAY        = 0.999\n",
        "WARMUP_EPOCHS    = 2         # Linear LR warmup at start of Phase 2\n",
        "\n",
        "# Model selection: EVA-02-Large requires timm\n",
        "ARCHITECTURES = [\"swin_v2_b\", \"convnext_base\"]\n",
        "if TIMM_AVAILABLE:\n",
        "    ARCHITECTURES.append(\"eva02_large\")\n",
        "\n",
        "print(f\"[Config] Architectures : {ARCHITECTURES}\")\n",
        "print(f\"[Config] Ensemble size : {len(ARCHITECTURES) * N_FOLDS} base models\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2 — Augmentation & Mixing Engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Augmentation] 12 TTA passes configured.\n"
          ]
        }
      ],
      "source": [
        "MEAN = [0.485, 0.456, 0.406]\n",
        "STD  = [0.229, 0.224, 0.225]\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE + 32, IMG_SIZE + 32)),\n",
        "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.7, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.05),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(MEAN, STD),\n",
        "    transforms.RandomErasing(p=0.2, scale=(0.02, 0.15)),\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE + 32, IMG_SIZE + 32)),\n",
        "    transforms.CenterCrop(IMG_SIZE),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(MEAN, STD),\n",
        "])\n",
        "\n",
        "\n",
        "class FixedCrop:\n",
        "    \"\"\"Deterministic crop at a fixed pixel position for TTA.\"\"\"\n",
        "    def __init__(self, top, left, height, width):\n",
        "        self.top, self.left, self.height, self.width = top, left, height, width\n",
        "\n",
        "    def __call__(self, img):\n",
        "        return transforms.functional.crop(img, self.top, self.left, self.height, self.width)\n",
        "\n",
        "\n",
        "_SZ, _LG = IMG_SIZE, int(IMG_SIZE * 1.15)\n",
        "\n",
        "def _compose(*tfms):\n",
        "    \"\"\"Helper to build transform pipeline with normalization.\"\"\"\n",
        "    return transforms.Compose(list(tfms) + [transforms.ToTensor(), transforms.Normalize(MEAN, STD)])\n",
        "\n",
        "tta_transforms_list = [\n",
        "    val_transforms,                                                                          # 1  Standard\n",
        "    _compose(transforms.Resize((_SZ, _SZ)), transforms.RandomHorizontalFlip(p=1.0)),        # 2  H-Flip\n",
        "    _compose(transforms.Resize((_LG, _LG)), transforms.CenterCrop(_SZ)),                    # 3  Zoom\n",
        "    _compose(transforms.Resize((_LG, _LG)), transforms.CenterCrop(_SZ),\n",
        "             transforms.RandomHorizontalFlip(p=1.0)),                                        # 4  Zoom+Flip\n",
        "    _compose(transforms.Resize((_SZ, _SZ)), transforms.RandomRotation((10, 10))),            # 5  Rot+10\n",
        "    _compose(transforms.Resize((_SZ, _SZ)), transforms.RandomRotation((-10, -10))),          # 6  Rot-10\n",
        "    _compose(transforms.Resize((_SZ, _SZ)), transforms.ColorJitter(0.2, 0.2)),               # 7  Color\n",
        "    _compose(transforms.Resize((_LG, _LG)), FixedCrop(0,       0,       _SZ, _SZ)),         # 8  TL\n",
        "    _compose(transforms.Resize((_LG, _LG)), FixedCrop(0,       _LG-_SZ, _SZ, _SZ)),        # 9  TR\n",
        "    _compose(transforms.Resize((_LG, _LG)), FixedCrop(_LG-_SZ, 0,       _SZ, _SZ)),        # 10 BL\n",
        "    _compose(transforms.Resize((_LG, _LG)), FixedCrop(_LG-_SZ, _LG-_SZ, _SZ, _SZ)),       # 11 BR\n",
        "    _compose(transforms.Resize((_SZ, _SZ)), transforms.GaussianBlur(3, sigma=0.5)),         # 12 Blur\n",
        "]\n",
        "\n",
        "\n",
        "def _rand_bbox(W, H, lam):\n",
        "    \"\"\"Random bounding box for CutMix.\"\"\"\n",
        "    cut = np.sqrt(1.0 - lam)\n",
        "    cw, ch = int(W * cut), int(H * cut)\n",
        "    cx, cy = np.random.randint(W), np.random.randint(H)\n",
        "    return (int(np.clip(cx - cw // 2, 0, W)), int(np.clip(cy - ch // 2, 0, H)),\n",
        "            int(np.clip(cx + cw // 2, 0, W)), int(np.clip(cy + ch // 2, 0, H)))\n",
        "\n",
        "\n",
        "def apply_mixup_cutmix(images, labels):\n",
        "    \"\"\"Apply either Mixup or CutMix with 50/50 probability.\"\"\"\n",
        "    use_cutmix = random.random() > 0.5\n",
        "    alpha = CUTMIX_ALPHA if use_cutmix else MIXUP_ALPHA\n",
        "    lam = np.random.beta(alpha, alpha)\n",
        "    perm = torch.randperm(images.size(0), device=images.device)\n",
        "\n",
        "    if use_cutmix:\n",
        "        mixed = images.clone()\n",
        "        x1, y1, x2, y2 = _rand_bbox(images.size(3), images.size(2), lam)\n",
        "        mixed[:, :, y1:y2, x1:x2] = images[perm, :, y1:y2, x1:x2]\n",
        "        lam = 1.0 - (x2 - x1) * (y2 - y1) / (images.size(2) * images.size(3))\n",
        "    else:\n",
        "        mixed = lam * images + (1.0 - lam) * images[perm]\n",
        "\n",
        "    return mixed, labels, labels[perm], lam\n",
        "\n",
        "\n",
        "print(f\"[Augmentation] {len(tta_transforms_list)} TTA passes configured.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3 — Datasets & Stratified K-Fold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Dataset] Classes     : ['chihuahua', 'muffin']\n",
            "[Dataset] Train images: 4733\n",
            "[Dataset] Test images : 1138\n",
            "[Dataset] K-Folds     : 5 (stratified)\n"
          ]
        }
      ],
      "source": [
        "class TransformSubset(Dataset):\n",
        "    \"\"\"Wraps an ImageFolder subset with a custom transform.\"\"\"\n",
        "    def __init__(self, dataset, indices, transform=None):\n",
        "        self.dataset = dataset\n",
        "        self.indices = indices\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image, label = self.dataset[self.indices[idx]]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "\n",
        "class TestDataset(Dataset):\n",
        "    \"\"\"Loads test images from a flat directory.\"\"\"\n",
        "    def __init__(self, test_dir, transform=None):\n",
        "        self.test_dir = test_dir\n",
        "        self.transform = transform\n",
        "        self.filenames = sorted([\n",
        "            f for f in os.listdir(test_dir)\n",
        "            if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filenames)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        name = self.filenames[idx]\n",
        "        image = Image.open(os.path.join(self.test_dir, name)).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, name\n",
        "\n",
        "\n",
        "class PseudoLabelDataset(Dataset):\n",
        "    \"\"\"Combines labeled training data with pseudo-labeled test images.\"\"\"\n",
        "    def __init__(self, original_dataset, original_indices, pseudo_paths, pseudo_labels, transform):\n",
        "        self.original_dataset = original_dataset\n",
        "        self.original_indices = original_indices\n",
        "        self.pseudo_paths = pseudo_paths\n",
        "        self.pseudo_labels = pseudo_labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.original_indices) + len(self.pseudo_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if idx < len(self.original_indices):\n",
        "            image, label = self.original_dataset[self.original_indices[idx]]\n",
        "        else:\n",
        "            pi = idx - len(self.original_indices)\n",
        "            image = Image.open(self.pseudo_paths[pi]).convert(\"RGB\")\n",
        "            label = self.pseudo_labels[pi]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "\n",
        "full_dataset = datasets.ImageFolder(root=TRAIN_DIR, transform=None)\n",
        "CLASS_NAMES  = full_dataset.classes\n",
        "IDX_TO_CLASS = {v: k for k, v in full_dataset.class_to_idx.items()}\n",
        "\n",
        "skf   = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
        "FOLDS = list(skf.split(np.zeros(len(full_dataset)), full_dataset.targets))\n",
        "\n",
        "print(f\"[Dataset] Classes     : {CLASS_NAMES}\")\n",
        "print(f\"[Dataset] Train images: {len(full_dataset)}\")\n",
        "print(f\"[Dataset] Test images : {len(TestDataset(TEST_DIR))}\")\n",
        "print(f\"[Dataset] K-Folds     : {N_FOLDS} (stratified)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4 — SAM Optimizer, EMA & Model Factory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Components] SAM, EMA, Model Factory ready.\n"
          ]
        }
      ],
      "source": [
        "class SAM(torch.optim.Optimizer):\n",
        "    \"\"\"\n",
        "    Sharpness-Aware Minimization (Foret et al., Google Research 2021).\n",
        "\n",
        "    Two-step weight update that seeks flat minima for better generalization.\n",
        "    Used by Kaggle Grandmaster winning solutions and Google's internal training.\n",
        "    \"\"\"\n",
        "    def __init__(self, params, base_optimizer_cls, rho=0.05, **kwargs):\n",
        "        defaults = dict(rho=rho, **kwargs)\n",
        "        super().__init__(params, defaults)\n",
        "        self.base_optimizer = base_optimizer_cls(self.param_groups, **kwargs)\n",
        "        self.param_groups = self.base_optimizer.param_groups\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def first_step(self, zero_grad=False):\n",
        "        grad_norm = self._grad_norm()\n",
        "        for group in self.param_groups:\n",
        "            scale = group[\"rho\"] / (grad_norm + 1e-12)\n",
        "            for p in group[\"params\"]:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                perturbation = p.grad * scale\n",
        "                p.add_(perturbation)\n",
        "                self.state[p][\"perturbation\"] = perturbation\n",
        "        if zero_grad:\n",
        "            self.zero_grad()\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def second_step(self, zero_grad=False):\n",
        "        for group in self.param_groups:\n",
        "            for p in group[\"params\"]:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                p.sub_(self.state[p][\"perturbation\"])\n",
        "        self.base_optimizer.step()\n",
        "        if zero_grad:\n",
        "            self.zero_grad()\n",
        "\n",
        "    def _grad_norm(self):\n",
        "        shared_device = self.param_groups[0][\"params\"][0].device\n",
        "        norms = [\n",
        "            p.grad.norm(2).to(shared_device)\n",
        "            for group in self.param_groups\n",
        "            for p in group[\"params\"]\n",
        "            if p.grad is not None\n",
        "        ]\n",
        "        return torch.norm(torch.stack(norms), 2)\n",
        "\n",
        "    def step(self, closure=None):\n",
        "        pass\n",
        "\n",
        "\n",
        "class ModelEMA:\n",
        "    \"\"\"Exponential Moving Average of model weights for stable inference.\"\"\"\n",
        "    def __init__(self, model, decay=0.999):\n",
        "        self.model = copy.deepcopy(model).eval()\n",
        "        self.decay = decay\n",
        "        for p in self.model.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "    def update(self, source_model):\n",
        "        with torch.no_grad():\n",
        "            for ema_val, model_val in zip(\n",
        "                self.model.state_dict().values(),\n",
        "                source_model.state_dict().values(),\n",
        "            ):\n",
        "                ema_val.copy_(self.decay * ema_val + (1.0 - self.decay) * model_val)\n",
        "\n",
        "\n",
        "def create_model(architecture, num_classes=2, freeze_backbone=True):\n",
        "    \"\"\"\n",
        "    Model factory supporting:\n",
        "      - swin_v2_b     (torchvision, 88M params)\n",
        "      - convnext_base (torchvision, 89M params)\n",
        "      - eva02_large   (timm, 304M params — strongest backbone, 90.0% ImageNet top-1)\n",
        "    \"\"\"\n",
        "    if architecture == \"swin_v2_b\":\n",
        "        model = models.swin_v2_b(weights=models.Swin_V2_B_Weights.IMAGENET1K_V1)\n",
        "        backbone_params = list(model.features.parameters())\n",
        "        model.head = nn.Linear(model.head.in_features, num_classes)\n",
        "\n",
        "    elif architecture == \"convnext_base\":\n",
        "        model = models.convnext_base(weights=models.ConvNeXt_Base_Weights.IMAGENET1K_V1)\n",
        "        backbone_params = list(model.features.parameters())\n",
        "        model.classifier[2] = nn.Linear(model.classifier[2].in_features, num_classes)\n",
        "\n",
        "    elif architecture == \"eva02_large\" and TIMM_AVAILABLE:\n",
        "        model = timm.create_model(\n",
        "            \"eva02_large_patch14_448.mim_m38m_ft_in22k_in1k\",\n",
        "            pretrained=True, num_classes=num_classes, img_size=IMG_SIZE,\n",
        "        )\n",
        "        head_names = {\"head\", \"head_drop\", \"fc_norm\"}\n",
        "        backbone_params = [\n",
        "            p for n, p in model.named_parameters()\n",
        "            if not any(h in n for h in head_names)\n",
        "        ]\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown architecture: {architecture}\")\n",
        "\n",
        "    if freeze_backbone:\n",
        "        for param in backbone_params:\n",
        "            param.requires_grad = False\n",
        "\n",
        "    n_total = sum(p.numel() for p in model.parameters())\n",
        "    n_train = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(f\"  [{architecture}] {n_total:,} params total, {n_train:,} trainable\")\n",
        "\n",
        "    return model.to(device)\n",
        "\n",
        "\n",
        "print(\"[Components] SAM, EMA, Model Factory ready.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5 — Checkpoint Manager (Google/NVIDIA Pattern)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Checkpoint] Manager ready.\n"
          ]
        }
      ],
      "source": [
        "PROGRESS_FILE = os.path.join(CKPT_DIR, \"progress.json\")\n",
        "\n",
        "\n",
        "def _load_progress():\n",
        "    \"\"\"Load training progress from disk.\"\"\"\n",
        "    if os.path.exists(PROGRESS_FILE):\n",
        "        with open(PROGRESS_FILE, \"r\") as f:\n",
        "            return json.load(f)\n",
        "    return {\"completed_folds\": {}, \"histories\": {}}\n",
        "\n",
        "\n",
        "def _save_progress(progress):\n",
        "    \"\"\"Persist training progress to disk.\"\"\"\n",
        "    with open(PROGRESS_FILE, \"w\") as f:\n",
        "        json.dump(progress, f, indent=2)\n",
        "\n",
        "\n",
        "def _fold_key(architecture, fold):\n",
        "    \"\"\"Unique key for architecture + fold combination.\"\"\"\n",
        "    return f\"{architecture}_f{fold}\"\n",
        "\n",
        "\n",
        "def save_training_checkpoint(architecture, fold, epoch, model, ema, optimizer,\n",
        "                             scheduler, scaler, best_val_acc, best_weights,\n",
        "                             no_improve, history):\n",
        "    \"\"\"\n",
        "    Save full training state for mid-fold resume.\n",
        "\n",
        "    Follows Google/NVIDIA best practice: saves model + optimizer + scheduler +\n",
        "    scaler + RNG states + metadata for exact reproducibility on resume.\n",
        "    \"\"\"\n",
        "    path = os.path.join(CKPT_DIR, f\"{_fold_key(architecture, fold)}_resume.pth\")\n",
        "    state = {\n",
        "        \"epoch\": epoch,\n",
        "        \"model_state\": model.state_dict(),\n",
        "        \"ema_state\": ema.model.state_dict(),\n",
        "        \"optimizer_state\": (\n",
        "            optimizer.base_optimizer.state_dict()\n",
        "            if isinstance(optimizer, SAM)\n",
        "            else optimizer.state_dict()\n",
        "        ),\n",
        "        \"scheduler_state\": scheduler.state_dict(),\n",
        "        \"scaler_state\": scaler.state_dict(),\n",
        "        \"best_val_acc\": best_val_acc,\n",
        "        \"best_weights\": best_weights,\n",
        "        \"no_improve\": no_improve,\n",
        "        \"history\": history,\n",
        "        \"rng_torch\": torch.get_rng_state(),\n",
        "        \"rng_numpy\": np.random.get_state(),\n",
        "        \"rng_python\": random.getstate(),\n",
        "    }\n",
        "    torch.save(state, path)\n",
        "\n",
        "\n",
        "def load_training_checkpoint(architecture, fold):\n",
        "    \"\"\"Load training state if a resume checkpoint exists.\"\"\"\n",
        "    path = os.path.join(CKPT_DIR, f\"{_fold_key(architecture, fold)}_resume.pth\")\n",
        "    if os.path.exists(path):\n",
        "        return torch.load(path, weights_only=False, map_location=device)\n",
        "    return None\n",
        "\n",
        "\n",
        "def clear_resume_checkpoint(architecture, fold):\n",
        "    \"\"\"Remove resume checkpoint after fold completes successfully.\"\"\"\n",
        "    path = os.path.join(CKPT_DIR, f\"{_fold_key(architecture, fold)}_resume.pth\")\n",
        "    if os.path.exists(path):\n",
        "        os.remove(path)\n",
        "\n",
        "\n",
        "print(\"[Checkpoint] Manager ready.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6 — Training Engine (with Checkpoint/Resume)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Engine] Training and inference ready (with checkpoint/resume).\n"
          ]
        }
      ],
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model, dataloader, criterion=None):\n",
        "    \"\"\"Evaluate model on a dataloader. Returns (accuracy, avg_loss, predictions, labels).\"\"\"\n",
        "    model.eval()\n",
        "    correct, total, running_loss = 0, 0, 0.0\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    for images, labels in dataloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        with autocast(AMP_DTYPE, enabled=AMP_ENABLED):\n",
        "            logits = model(images)\n",
        "            if criterion:\n",
        "                running_loss += criterion(logits, labels).item() * labels.size(0)\n",
        "        preds = logits.argmax(dim=1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = 100.0 * correct / total\n",
        "    avg_loss = running_loss / total if criterion else 0.0\n",
        "    return accuracy, avg_loss, np.array(all_preds), np.array(all_labels)\n",
        "\n",
        "\n",
        "def train_fold(architecture, fold_idx, save_path):\n",
        "    \"\"\"\n",
        "    Two-phase training pipeline with full checkpoint/resume support.\n",
        "\n",
        "    Phase 1 — Head warmup with AdamW + Gradient Accumulation (frozen backbone)\n",
        "    Phase 2 — Full SAM fine-tune with EMA, Mixup/CutMix, Warmup + CosineWarmRestarts\n",
        "\n",
        "    Can be stopped at any time — will resume from the last completed epoch.\n",
        "\n",
        "    Returns: (best_val_acc, history_dict)\n",
        "    \"\"\"\n",
        "    fold_key = _fold_key(architecture, fold_idx)\n",
        "    progress = _load_progress()\n",
        "\n",
        "    # Skip if already completed\n",
        "    if fold_key in progress.get(\"completed_folds\", {}):\n",
        "        best = progress[\"completed_folds\"][fold_key]\n",
        "        hist = progress.get(\"histories\", {}).get(fold_key, {})\n",
        "        print(f\"\\n  [SKIP] {architecture} Fold {fold_idx} — already completed (best={best:.2f}%)\")\n",
        "        return best, hist\n",
        "\n",
        "    print(f\"\\n{'=' * 60}\")\n",
        "    print(f\"  {architecture} | Fold {fold_idx}\")\n",
        "    print(f\"{'=' * 60}\")\n",
        "\n",
        "    # --- DataLoaders ---\n",
        "    train_idx, val_idx = FOLDS[fold_idx]\n",
        "    train_loader = DataLoader(\n",
        "        TransformSubset(full_dataset, train_idx, train_transforms),\n",
        "        batch_size=BATCH_SIZE, shuffle=True,\n",
        "        num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY,\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        TransformSubset(full_dataset, val_idx, val_transforms),\n",
        "        batch_size=BATCH_SIZE, shuffle=False,\n",
        "        num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY,\n",
        "    )\n",
        "\n",
        "    # --- Model & Training Components ---\n",
        "    model = create_model(architecture, freeze_backbone=True)\n",
        "    ema = ModelEMA(model, decay=EMA_DECAY)\n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=LABEL_SMOOTHING)\n",
        "    scaler = GradScaler(enabled=AMP_ENABLED)\n",
        "\n",
        "    history = {\"train_loss\": [], \"val_loss\": [], \"train_acc\": [], \"val_acc\": [], \"phase\": []}\n",
        "    best_val_acc, best_weights, no_improve = 0.0, None, 0\n",
        "    start_epoch_p1, start_epoch_p2 = 1, 1\n",
        "\n",
        "    # --- Check for resume checkpoint ---\n",
        "    ckpt = load_training_checkpoint(architecture, fold_idx)\n",
        "    resume_phase = None\n",
        "    if ckpt:\n",
        "        history = ckpt[\"history\"]\n",
        "        best_val_acc = ckpt[\"best_val_acc\"]\n",
        "        best_weights = ckpt[\"best_weights\"]\n",
        "        no_improve = ckpt[\"no_improve\"]\n",
        "        torch.set_rng_state(ckpt[\"rng_torch\"])\n",
        "        np.random.set_state(ckpt[\"rng_numpy\"])\n",
        "        random.setstate(ckpt[\"rng_python\"])\n",
        "\n",
        "        last_phase = history[\"phase\"][-1] if history[\"phase\"] else 0\n",
        "        last_epoch = ckpt[\"epoch\"]\n",
        "\n",
        "        if last_phase == 1:\n",
        "            start_epoch_p1 = last_epoch + 1\n",
        "            resume_phase = 1\n",
        "        else:\n",
        "            start_epoch_p1 = P1_EPOCHS + 1  # skip Phase 1\n",
        "            start_epoch_p2 = last_epoch + 1\n",
        "            resume_phase = 2\n",
        "        print(f\"  [RESUME] Phase {resume_phase}, epoch {last_epoch + 1}\")\n",
        "\n",
        "    # ==================================================================\n",
        "    #  Phase 1: Head Warmup (frozen backbone)\n",
        "    # ==================================================================\n",
        "    if start_epoch_p1 <= P1_EPOCHS:\n",
        "        head_optimizer = optim.AdamW(\n",
        "            filter(lambda p: p.requires_grad, model.parameters()),\n",
        "            lr=P1_LR, weight_decay=WEIGHT_DECAY,\n",
        "        )\n",
        "        if resume_phase == 1 and ckpt:\n",
        "            model.load_state_dict(ckpt[\"model_state\"])\n",
        "            ema.model.load_state_dict(ckpt[\"ema_state\"])\n",
        "            head_optimizer.load_state_dict(ckpt[\"optimizer_state\"])\n",
        "            scaler.load_state_dict(ckpt[\"scaler_state\"])\n",
        "\n",
        "        print(f\"\\n  Phase 1: Head warmup (epoch {start_epoch_p1}-{P1_EPOCHS})\")\n",
        "        for epoch in range(start_epoch_p1, P1_EPOCHS + 1):\n",
        "            model.train()\n",
        "            head_optimizer.zero_grad()\n",
        "            epoch_loss, epoch_correct, epoch_total = 0.0, 0, 0\n",
        "\n",
        "            for step, (images, labels) in enumerate(tqdm(train_loader, leave=False, desc=f\"P1 E{epoch}\")):\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                with autocast(AMP_DTYPE, enabled=AMP_ENABLED):\n",
        "                    logits = model(images)\n",
        "                    loss = criterion(logits, labels)\n",
        "                scaler.scale(loss / GRAD_ACCUM).backward()\n",
        "                epoch_loss += loss.item() * labels.size(0)\n",
        "                epoch_correct += (logits.argmax(1) == labels).sum().item()\n",
        "                epoch_total += labels.size(0)\n",
        "\n",
        "                if (step + 1) % GRAD_ACCUM == 0 or (step + 1) == len(train_loader):\n",
        "                    scaler.unscale_(head_optimizer)\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP)\n",
        "                    scaler.step(head_optimizer)\n",
        "                    scaler.update()\n",
        "                    head_optimizer.zero_grad()\n",
        "                    ema.update(model)\n",
        "\n",
        "            train_acc = 100.0 * epoch_correct / epoch_total\n",
        "            train_loss = epoch_loss / epoch_total\n",
        "            val_acc, val_loss, _, _ = evaluate(ema.model, val_loader, criterion)\n",
        "\n",
        "            history[\"train_loss\"].append(train_loss)\n",
        "            history[\"val_loss\"].append(val_loss)\n",
        "            history[\"train_acc\"].append(train_acc)\n",
        "            history[\"val_acc\"].append(val_acc)\n",
        "            history[\"phase\"].append(1)\n",
        "\n",
        "            marker = \" *\" if val_acc > best_val_acc else \"\"\n",
        "            print(f\"    E{epoch}/{P1_EPOCHS}  t_loss={train_loss:.4f}  v_loss={val_loss:.4f}  \"\n",
        "                  f\"t_acc={train_acc:.2f}%  v_acc={val_acc:.2f}%{marker}\")\n",
        "\n",
        "            if val_acc > best_val_acc:\n",
        "                best_val_acc = val_acc\n",
        "                best_weights = copy.deepcopy(ema.model.state_dict())\n",
        "\n",
        "            # Save checkpoint after each epoch\n",
        "            dummy_scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(head_optimizer, T_0=10)\n",
        "            save_training_checkpoint(\n",
        "                architecture, fold_idx, epoch, model, ema, head_optimizer,\n",
        "                dummy_scheduler, scaler, best_val_acc, best_weights, no_improve, history,\n",
        "            )\n",
        "\n",
        "    # ==================================================================\n",
        "    #  Phase 2: Full SAM Fine-tune with Warmup + CosineWarmRestarts\n",
        "    # ==================================================================\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "    sam_optimizer = SAM(\n",
        "        model.parameters(), optim.AdamW,\n",
        "        rho=SAM_RHO, lr=P2_LR, weight_decay=WEIGHT_DECAY,\n",
        "    )\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "        sam_optimizer.base_optimizer, T_0=10, T_mult=1, eta_min=1e-7,\n",
        "    )\n",
        "\n",
        "    if resume_phase == 2 and ckpt:\n",
        "        model.load_state_dict(ckpt[\"model_state\"])\n",
        "        ema.model.load_state_dict(ckpt[\"ema_state\"])\n",
        "        sam_optimizer.base_optimizer.load_state_dict(ckpt[\"optimizer_state\"])\n",
        "        scheduler.load_state_dict(ckpt[\"scheduler_state\"])\n",
        "        scaler.load_state_dict(ckpt[\"scaler_state\"])\n",
        "\n",
        "    n_trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(f\"\\n  Phase 2: SAM fine-tune ({n_trainable:,} params, epoch {start_epoch_p2}-{P2_EPOCHS})\")\n",
        "\n",
        "    for epoch in range(start_epoch_p2, P2_EPOCHS + 1):\n",
        "        model.train()\n",
        "        epoch_loss, epoch_correct, epoch_total = 0.0, 0, 0\n",
        "\n",
        "        # Linear warmup: scale LR from 10% to 100% over WARMUP_EPOCHS\n",
        "        if epoch <= WARMUP_EPOCHS:\n",
        "            warmup_lr = P2_LR * (0.1 + 0.9 * (epoch / WARMUP_EPOCHS))\n",
        "            for param_group in sam_optimizer.base_optimizer.param_groups:\n",
        "                param_group[\"lr\"] = warmup_lr\n",
        "\n",
        "        for images, labels in tqdm(train_loader, leave=False, desc=f\"P2 E{epoch:02d}\"):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # Pre-compute mixed data ONCE for SAM consistency\n",
        "            use_mix = random.random() < MIX_PROB\n",
        "            if use_mix:\n",
        "                mixed, labels_a, labels_b, lam = apply_mixup_cutmix(images, labels)\n",
        "            else:\n",
        "                mixed, labels_a, labels_b, lam = images, labels, labels, 1.0\n",
        "\n",
        "            # SAM Pass 1: Compute gradients and perturb weights\n",
        "            with autocast(AMP_DTYPE, enabled=AMP_ENABLED):\n",
        "                logits = model(mixed)\n",
        "                loss = lam * criterion(logits, labels_a) + (1.0 - lam) * criterion(logits, labels_b)\n",
        "            loss.backward()\n",
        "            sam_optimizer.first_step(zero_grad=True)\n",
        "\n",
        "            # SAM Pass 2: Compute gradients at perturbed point and update\n",
        "            with autocast(AMP_DTYPE, enabled=AMP_ENABLED):\n",
        "                logits = model(mixed)\n",
        "                loss = lam * criterion(logits, labels_a) + (1.0 - lam) * criterion(logits, labels_b)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP)\n",
        "            sam_optimizer.second_step(zero_grad=True)\n",
        "            ema.update(model)\n",
        "\n",
        "            epoch_loss += loss.item() * labels.size(0)\n",
        "            epoch_correct += (logits.argmax(1) == labels_a).sum().item()\n",
        "            epoch_total += labels.size(0)\n",
        "\n",
        "        if epoch > WARMUP_EPOCHS:\n",
        "            scheduler.step()\n",
        "\n",
        "        train_acc = 100.0 * epoch_correct / epoch_total\n",
        "        train_loss = epoch_loss / epoch_total\n",
        "        val_acc, val_loss, _, _ = evaluate(ema.model, val_loader, criterion)\n",
        "\n",
        "        history[\"train_loss\"].append(train_loss)\n",
        "        history[\"val_loss\"].append(val_loss)\n",
        "        history[\"train_acc\"].append(train_acc)\n",
        "        history[\"val_acc\"].append(val_acc)\n",
        "        history[\"phase\"].append(2)\n",
        "\n",
        "        marker = \" * BEST\" if val_acc > best_val_acc else \"\"\n",
        "        print(f\"    E{epoch:02d}/{P2_EPOCHS}  t_loss={train_loss:.4f}  v_loss={val_loss:.4f}  \"\n",
        "              f\"t_acc={train_acc:.2f}%  v_acc={val_acc:.2f}%{marker}\")\n",
        "\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            best_weights = copy.deepcopy(ema.model.state_dict())\n",
        "            torch.save(best_weights, save_path)\n",
        "            no_improve = 0\n",
        "        else:\n",
        "            no_improve += 1\n",
        "            if no_improve >= PATIENCE:\n",
        "                print(f\"    Early stopping at epoch {epoch}.\")\n",
        "                break\n",
        "\n",
        "        save_training_checkpoint(\n",
        "            architecture, fold_idx, epoch, model, ema, sam_optimizer,\n",
        "            scheduler, scaler, best_val_acc, best_weights, no_improve, history,\n",
        "        )\n",
        "\n",
        "    # --- Mark fold as completed ---\n",
        "    progress = _load_progress()\n",
        "    if \"completed_folds\" not in progress:\n",
        "        progress[\"completed_folds\"] = {}\n",
        "    if \"histories\" not in progress:\n",
        "        progress[\"histories\"] = {}\n",
        "    progress[\"completed_folds\"][fold_key] = best_val_acc\n",
        "    progress[\"histories\"][fold_key] = history\n",
        "    _save_progress(progress)\n",
        "    clear_resume_checkpoint(architecture, fold_idx)\n",
        "\n",
        "    del model, ema, sam_optimizer, criterion, scaler\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    print(f\"  Finished. Best val accuracy: {best_val_acc:.2f}%\\n\")\n",
        "    return best_val_acc, history\n",
        "\n",
        "\n",
        "def ensemble_inference(model_configs, tta_list, test_dir):\n",
        "    \"\"\"Memory-efficient sequential ensemble inference: one model at a time.\"\"\"\n",
        "    softmax_fn = nn.Softmax(dim=1)\n",
        "    accumulated_probs, filenames = None, None\n",
        "    total_passes = len(model_configs) * len(tta_list)\n",
        "\n",
        "    for model_idx, (arch, weight_path) in enumerate(model_configs):\n",
        "        print(f\"  [{model_idx + 1}/{len(model_configs)}] {arch} <- {weight_path}\")\n",
        "        model = create_model(arch, freeze_backbone=False)\n",
        "        model.load_state_dict(torch.load(weight_path, weights_only=True, map_location=device))\n",
        "        model.eval()\n",
        "\n",
        "        for tta_transform in tta_list:\n",
        "            loader = DataLoader(\n",
        "                TestDataset(test_dir, transform=tta_transform),\n",
        "                batch_size=BATCH_SIZE, shuffle=False,\n",
        "                num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY,\n",
        "            )\n",
        "            batch_probs, batch_names = [], []\n",
        "            with torch.no_grad():\n",
        "                for images, names in loader:\n",
        "                    with autocast(AMP_DTYPE, enabled=AMP_ENABLED):\n",
        "                        probs = softmax_fn(model(images.to(device))).cpu().numpy()\n",
        "                        batch_probs.append(probs)\n",
        "                    if filenames is None:\n",
        "                        batch_names.extend(names)\n",
        "\n",
        "            pass_probs = np.concatenate(batch_probs, axis=0)\n",
        "            if accumulated_probs is None:\n",
        "                accumulated_probs, filenames = pass_probs, batch_names\n",
        "            else:\n",
        "                accumulated_probs += pass_probs\n",
        "\n",
        "        del model\n",
        "        gc.collect()\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    accumulated_probs /= total_passes\n",
        "    return accumulated_probs, filenames\n",
        "\n",
        "\n",
        "print(\"[Engine] Training and inference ready (with checkpoint/resume).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7 — Visualization Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Visualization] Ready.\n"
          ]
        }
      ],
      "source": [
        "def plot_training_history(history, title=\"Training History\"):\n",
        "    \"\"\"Dual-panel plot: accuracy and loss curves with phase boundary.\"\"\"\n",
        "    epochs = list(range(1, len(history[\"train_loss\"]) + 1))\n",
        "    fig, (ax_acc, ax_loss) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "    fig.suptitle(title, fontsize=14, fontweight=\"bold\")\n",
        "\n",
        "    phase_boundary = sum(1 for p in history[\"phase\"] if p == 1)\n",
        "\n",
        "    for ax, suffix, ylabel, loc in [\n",
        "        (ax_acc, \"_acc\", \"Accuracy (%)\", \"lower right\"),\n",
        "        (ax_loss, \"_loss\", \"Loss\", \"upper right\"),\n",
        "    ]:\n",
        "        ax.plot(epochs, history[\"train\" + suffix], \"b-o\", ms=3, label=\"Train\")\n",
        "        ax.plot(epochs, history[\"val\" + suffix], \"r-o\", ms=3, label=\"Validation\")\n",
        "        if phase_boundary < len(epochs):\n",
        "            ax.axvline(x=phase_boundary + 0.5, color=\"gray\", ls=\"--\", alpha=0.5, label=\"Phase 1|2\")\n",
        "        ax.set_xlabel(\"Epoch\")\n",
        "        ax.set_ylabel(ylabel)\n",
        "        ax.legend(loc=loc)\n",
        "        ax.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    fname = title.replace(\" \", \"_\").lower() + \".png\"\n",
        "    plt.savefig(fname, dpi=150, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "    print(f\"  Saved: {fname}\")\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, class_names, title=\"Confusion Matrix\"):\n",
        "    \"\"\"Heatmap confusion matrix with counts and percentages.\"\"\"\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    cm_pct = cm.astype(float) / cm.sum(axis=1, keepdims=True) * 100\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "                xticklabels=class_names, yticklabels=class_names, ax=ax)\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j + 0.5, i + 0.72, f\"({cm_pct[i, j]:.1f}%)\",\n",
        "                    ha=\"center\", va=\"center\", fontsize=9, color=\"gray\")\n",
        "    ax.set_xlabel(\"Predicted\")\n",
        "    ax.set_ylabel(\"True\")\n",
        "    ax.set_title(title, fontsize=14, fontweight=\"bold\")\n",
        "    plt.tight_layout()\n",
        "    fname = title.replace(\" \", \"_\").lower() + \".png\"\n",
        "    plt.savefig(fname, dpi=150, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "    print(f\"  Saved: {fname}\")\n",
        "\n",
        "\n",
        "def print_classification_report(y_true, y_pred, class_names, title=\"Classification Report\"):\n",
        "    \"\"\"Print sklearn classification report with header.\"\"\"\n",
        "    print(f\"\\n{'=' * 60}\")\n",
        "    print(f\"  {title}\")\n",
        "    print(f\"{'=' * 60}\")\n",
        "    print(classification_report(y_true, y_pred, target_names=class_names, digits=4))\n",
        "\n",
        "\n",
        "print(\"[Visualization] Ready.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8 — Train All Folds (Auto-Resumes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "  swin_v2_b | Fold 0\n",
            "============================================================\n",
            "  [swin_v2_b] 86,907,898 params total, 4,098 trainable\n",
            "\n",
            "  Phase 1: Head warmup (epoch 1-5)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                        \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    E1/5  t_loss=0.3331  v_loss=0.7152  t_acc=95.64%  v_acc=46.36% *\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                        \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    E2/5  t_loss=0.2301  v_loss=0.5687  t_acc=99.23%  v_acc=91.45% *\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                        \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    E3/5  t_loss=0.2280  v_loss=0.4639  t_acc=99.39%  v_acc=97.15% *\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                        \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    E4/5  t_loss=0.2247  v_loss=0.3926  t_acc=99.50%  v_acc=98.20% *\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                        \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    E5/5  t_loss=0.2232  v_loss=0.3444  t_acc=99.52%  v_acc=98.73% *\n",
            "\n",
            "  Phase 2: SAM fine-tune (86,907,898 params, epoch 1-30)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                           \r"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m fold \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N_FOLDS):\n\u001b[32m      9\u001b[39m     save_name = os.path.join(CKPT_DIR, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mbest_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00march\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_f\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.pth\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     acc, hist = \u001b[43mtrain_fold\u001b[49m\u001b[43m(\u001b[49m\u001b[43march\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m     all_results[arch][fold] = acc\n\u001b[32m     12\u001b[39m     all_histories[arch][fold] = hist\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 208\u001b[39m, in \u001b[36mtrain_fold\u001b[39m\u001b[34m(architecture, fold_idx, save_path)\u001b[39m\n\u001b[32m    206\u001b[39m     logits = model(mixed)\n\u001b[32m    207\u001b[39m     loss = lam * criterion(logits, labels_a) + (\u001b[32m1.0\u001b[39m - lam) * criterion(logits, labels_b)\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    209\u001b[39m sam_optimizer.first_step(zero_grad=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    211\u001b[39m \u001b[38;5;66;03m# SAM Pass 2: Compute gradients at perturbed point and update\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Muffyn/venv/lib/python3.14/site-packages/torch/_tensor.py:630\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    620\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    621\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    622\u001b[39m         Tensor.backward,\n\u001b[32m    623\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    628\u001b[39m         inputs=inputs,\n\u001b[32m    629\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m630\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    631\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    632\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Muffyn/venv/lib/python3.14/site-packages/torch/autograd/__init__.py:364\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    359\u001b[39m     retain_graph = create_graph\n\u001b[32m    361\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    362\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    363\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    365\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    366\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    368\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    369\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    370\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Muffyn/venv/lib/python3.14/site-packages/torch/autograd/graph.py:865\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    863\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    864\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m865\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    866\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    867\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    869\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "all_results = {}\n",
        "all_histories = {}\n",
        "\n",
        "for arch in ARCHITECTURES:\n",
        "    all_results[arch] = {}\n",
        "    all_histories[arch] = {}\n",
        "\n",
        "    for fold in range(N_FOLDS):\n",
        "        save_name = os.path.join(CKPT_DIR, f\"best_{arch}_f{fold}.pth\")\n",
        "        acc, hist = train_fold(arch, fold, save_name)\n",
        "        all_results[arch][fold] = acc\n",
        "        all_histories[arch][fold] = hist\n",
        "\n",
        "    avg = np.mean(list(all_results[arch].values()))\n",
        "    print(f\"\\n[{arch}] Average: {avg:.2f}%\")\n",
        "    if all_histories[arch].get(0):\n",
        "        plot_training_history(all_histories[arch][0], f\"{arch} Fold 0\")\n",
        "\n",
        "# Training Summary\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"  Training Summary\")\n",
        "print(\"=\" * 60)\n",
        "for arch in ARCHITECTURES:\n",
        "    avg = np.mean(list(all_results[arch].values()))\n",
        "    print(f\"  {arch:20s}: {avg:.2f}% avg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9 — Classification Report & Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"  Evaluation on Fold 0 Validation Set\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    TransformSubset(full_dataset, FOLDS[0][1], val_transforms),\n",
        "    batch_size=BATCH_SIZE, shuffle=False,\n",
        "    num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY,\n",
        ")\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=LABEL_SMOOTHING)\n",
        "\n",
        "for arch in ARCHITECTURES:\n",
        "    weight_path = os.path.join(CKPT_DIR, f\"best_{arch}_f0.pth\")\n",
        "    if not os.path.exists(weight_path):\n",
        "        print(f\"  {arch}: checkpoint not found, skipping\")\n",
        "        continue\n",
        "    model = create_model(arch, freeze_backbone=False)\n",
        "    model.load_state_dict(torch.load(weight_path, weights_only=True, map_location=device))\n",
        "    acc, loss, preds, labels = evaluate(model, val_loader, criterion)\n",
        "    print(f\"\\n  {arch} -> val_acc={acc:.2f}%  val_loss={loss:.4f}\")\n",
        "    print_classification_report(labels, preds, CLASS_NAMES, f\"{arch}\")\n",
        "    plot_confusion_matrix(labels, preds, CLASS_NAMES, f\"{arch} Confusion Matrix\")\n",
        "    del model\n",
        "    gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 10 — Round 1 Ensemble Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "round1_configs = []\n",
        "for arch in ARCHITECTURES:\n",
        "    for fold in range(N_FOLDS):\n",
        "        path = os.path.join(CKPT_DIR, f\"best_{arch}_f{fold}.pth\")\n",
        "        if os.path.exists(path):\n",
        "            round1_configs.append((arch, path))\n",
        "\n",
        "n_passes = len(round1_configs) * len(tta_transforms_list)\n",
        "print(f\"  Round 1: {len(round1_configs)} models x {len(tta_transforms_list)} TTA = {n_passes} passes\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "r1_probs, r1_filenames = ensemble_inference(round1_configs, tta_transforms_list, TEST_DIR)\n",
        "r1_pred_idx = np.argmax(r1_probs, axis=1)\n",
        "r1_preds = [IDX_TO_CLASS[i] for i in r1_pred_idx]\n",
        "r1_conf = np.max(r1_probs, axis=1)\n",
        "\n",
        "print(f\"\\n  Confidence  mean={r1_conf.mean():.4f}  min={r1_conf.min():.4f}\")\n",
        "print(f\"  High-conf (>{PSEUDO_THRESHOLD}): {(r1_conf > PSEUDO_THRESHOLD).sum()}/{len(r1_conf)}\")\n",
        "\n",
        "sub_r1 = pd.DataFrame({\"ID\": r1_filenames, \"Predict\": r1_preds})\n",
        "sub_r1.to_csv(\"submission_r1.csv\", index=False)\n",
        "print(f\"\\n  Round 1 saved -> submission_r1.csv ({len(sub_r1)} rows)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 11 — Consensus Pseudo-Labeling (with Previous Submission)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"  Consensus Pseudo-Labeling\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Load previous submission for consensus voting\n",
        "prev_labels = {}\n",
        "if os.path.exists(PREV_SUB):\n",
        "    prev_df = pd.read_csv(PREV_SUB)\n",
        "    prev_labels = dict(zip(prev_df.iloc[:, 0], prev_df.iloc[:, 1]))\n",
        "    print(f\"  Previous submission loaded: {len(prev_labels)} predictions (score=0.96315)\")\n",
        "else:\n",
        "    print(\"  No previous submission found. Using ensemble-only confidence.\")\n",
        "\n",
        "# Build pseudo-label candidates:\n",
        "# - Must exceed PSEUDO_THRESHOLD confidence from the new ensemble\n",
        "# - If previous submission exists, both must agree on the label (consensus)\n",
        "pseudo_paths = []\n",
        "pseudo_labels = []\n",
        "n_high_conf = 0\n",
        "n_consensus = 0\n",
        "class_to_idx = full_dataset.class_to_idx\n",
        "\n",
        "for i in range(len(r1_filenames)):\n",
        "    if r1_conf[i] <= PSEUDO_THRESHOLD:\n",
        "        continue\n",
        "    n_high_conf += 1\n",
        "\n",
        "    new_label = r1_preds[i]\n",
        "    if prev_labels:\n",
        "        old_label = prev_labels.get(r1_filenames[i])\n",
        "        if old_label != new_label:\n",
        "            continue  # Disagreement — skip this image\n",
        "        n_consensus += 1\n",
        "    else:\n",
        "        n_consensus += 1\n",
        "\n",
        "    pseudo_paths.append(os.path.join(TEST_DIR, r1_filenames[i]))\n",
        "    pseudo_labels.append(class_to_idx[new_label])\n",
        "\n",
        "n_pseudo = len(pseudo_paths)\n",
        "print(f\"  High-confidence (>{PSEUDO_THRESHOLD}): {n_high_conf}/{len(r1_conf)}\")\n",
        "if prev_labels:\n",
        "    print(f\"  Consensus (both agree): {n_consensus}/{n_high_conf}\")\n",
        "print(f\"  Final pseudo-labels: {n_pseudo}\")\n",
        "\n",
        "if n_pseudo > 0:\n",
        "    label_counts = dict(zip(*np.unique(pseudo_labels, return_counts=True)))\n",
        "    print(f\"  Label distribution: {label_counts}\")\n",
        "\n",
        "    for arch in ARCHITECTURES:\n",
        "        base_path = os.path.join(CKPT_DIR, f\"best_{arch}_f0.pth\")\n",
        "        pseudo_save_path = os.path.join(CKPT_DIR, f\"best_{arch}_pseudo.pth\")\n",
        "\n",
        "        if not os.path.exists(base_path):\n",
        "            continue\n",
        "\n",
        "        # Skip if already completed\n",
        "        if os.path.exists(pseudo_save_path):\n",
        "            print(f\"\\n  [SKIP] {arch} pseudo-labeling — already completed\")\n",
        "            continue\n",
        "\n",
        "        print(f\"\\n  Pseudo-retrain: {arch}\")\n",
        "\n",
        "        train_idx, val_idx = FOLDS[0]\n",
        "        pseudo_train_loader = DataLoader(\n",
        "            PseudoLabelDataset(full_dataset, train_idx, pseudo_paths, pseudo_labels, train_transforms),\n",
        "            batch_size=BATCH_SIZE, shuffle=True,\n",
        "            num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY,\n",
        "        )\n",
        "        pseudo_val_loader = DataLoader(\n",
        "            TransformSubset(full_dataset, val_idx, val_transforms),\n",
        "            batch_size=BATCH_SIZE, shuffle=False,\n",
        "            num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY,\n",
        "        )\n",
        "\n",
        "        model = create_model(arch, freeze_backbone=False)\n",
        "        model.load_state_dict(torch.load(base_path, weights_only=True, map_location=device))\n",
        "        ema = ModelEMA(model, EMA_DECAY)\n",
        "        crit = nn.CrossEntropyLoss(label_smoothing=LABEL_SMOOTHING)\n",
        "        opt = optim.AdamW(model.parameters(), lr=P2_LR * 0.5, weight_decay=WEIGHT_DECAY)\n",
        "        sched = optim.lr_scheduler.CosineAnnealingWarmRestarts(opt, T_0=5, T_mult=1, eta_min=1e-7)\n",
        "        grad_scaler = GradScaler(enabled=AMP_ENABLED)\n",
        "        best_pseudo_acc, no_improve_pseudo = 0.0, 0\n",
        "\n",
        "        for ep in range(1, 11):\n",
        "            model.train()\n",
        "            for images, labels in tqdm(pseudo_train_loader, leave=False, desc=f\"Pseudo E{ep}\"):\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                opt.zero_grad()\n",
        "                use_mix = random.random() < MIX_PROB\n",
        "                if use_mix:\n",
        "                    mixed, la, lb, lam = apply_mixup_cutmix(images, labels)\n",
        "                else:\n",
        "                    mixed, la, lb, lam = images, labels, labels, 1.0\n",
        "                with autocast(AMP_DTYPE, enabled=AMP_ENABLED):\n",
        "                    logits = model(mixed)\n",
        "                    loss = lam * crit(logits, la) + (1.0 - lam) * crit(logits, lb)\n",
        "                grad_scaler.scale(loss).backward()\n",
        "                grad_scaler.unscale_(opt)\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP)\n",
        "                grad_scaler.step(opt)\n",
        "                grad_scaler.update()\n",
        "                ema.update(model)\n",
        "            sched.step()\n",
        "\n",
        "            val_acc, val_loss, _, _ = evaluate(ema.model, pseudo_val_loader, crit)\n",
        "            marker = \" *\" if val_acc > best_pseudo_acc else \"\"\n",
        "            print(f\"    E{ep:02d}/10  val_acc={val_acc:.2f}%  val_loss={val_loss:.4f}{marker}\")\n",
        "\n",
        "            if val_acc > best_pseudo_acc:\n",
        "                best_pseudo_acc = val_acc\n",
        "                torch.save(copy.deepcopy(ema.model.state_dict()), pseudo_save_path)\n",
        "                no_improve_pseudo = 0\n",
        "            else:\n",
        "                no_improve_pseudo += 1\n",
        "                if no_improve_pseudo >= 5:\n",
        "                    print(f\"    Early stopping at epoch {ep}.\")\n",
        "                    break\n",
        "\n",
        "        del model, ema, opt, crit, grad_scaler\n",
        "        gc.collect()\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "        print(f\"  {arch} pseudo best: {best_pseudo_acc:.2f}%\")\n",
        "else:\n",
        "    print(\"  No pseudo-label candidates. Skipping.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 12 — Final Ensemble Submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"  Final Ensemble (All Models + Pseudo)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "final_configs = []\n",
        "for arch in ARCHITECTURES:\n",
        "    for fold in range(N_FOLDS):\n",
        "        path = os.path.join(CKPT_DIR, f\"best_{arch}_f{fold}.pth\")\n",
        "        if os.path.exists(path):\n",
        "            final_configs.append((arch, path))\n",
        "    pseudo_path = os.path.join(CKPT_DIR, f\"best_{arch}_pseudo.pth\")\n",
        "    if os.path.exists(pseudo_path):\n",
        "        final_configs.append((arch, pseudo_path))\n",
        "\n",
        "print(f\"  Models in final ensemble: {len(final_configs)}\")\n",
        "\n",
        "final_probs, final_filenames = ensemble_inference(final_configs, tta_transforms_list, TEST_DIR)\n",
        "final_preds = [IDX_TO_CLASS[i] for i in np.argmax(final_probs, axis=1)]\n",
        "final_conf = np.max(final_probs, axis=1)\n",
        "\n",
        "submission = pd.DataFrame({\"ID\": final_filenames, \"Predict\": final_preds})\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "\n",
        "print(f\"\\n  submission.csv saved ({len(submission)} rows)\")\n",
        "print(f\"  Confidence  mean={final_conf.mean():.4f}  min={final_conf.min():.4f}\")\n",
        "print(f\"\\n{submission['Predict'].value_counts().to_string()}\")\n",
        "print(\"\\n  Pipeline complete. Upload submission.csv to Kaggle.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
