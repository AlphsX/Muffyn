{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Import Libraries & SOTA Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using Apple MPS (GPU) üöÄ\n",
            "‚öôÔ∏è SOTA Setup Complete!\n"
          ]
        }
      ],
      "source": [
        "import ssl\n",
        "ssl._create_default_https_context = ssl._create_unverified_context\n",
        "\n",
        "import os, copy, random, gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, datasets, models\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ==========================================\n",
        "# Reproducibility & Determinism\n",
        "# ==========================================\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available(): \n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "# ==========================================\n",
        "# Device Setup\n",
        "# ==========================================\n",
        "if torch.backends.mps.is_available():\n",
        "    device = torch.device('mps'); print('Using Apple MPS (GPU) üöÄ')\n",
        "elif torch.cuda.is_available():\n",
        "    device = torch.device('cuda'); print(f'Using CUDA: {torch.cuda.get_device_name(0)}')\n",
        "else:\n",
        "    device = torch.device('cpu'); print('Using CPU')\n",
        "\n",
        "# ==========================================\n",
        "# Paths\n",
        "# ==========================================\n",
        "if os.path.exists('/kaggle/input'):\n",
        "    BASE_DIR = '/kaggle/input/cs-460-muffin-vs-chihuahua-classification-challenge'\n",
        "else:\n",
        "    BASE_DIR = './data'\n",
        "TRAIN_DIR = f'{BASE_DIR}/train'\n",
        "TEST_DIR  = f'{BASE_DIR}/kaggle_test_final'\n",
        "\n",
        "# ==========================================\n",
        "# SOTA Hyperparameters (2025/2026 Focus)\n",
        "# ==========================================\n",
        "IMG_SIZE        = 384      # 384x384 standard for ViTs (Swin)\n",
        "BATCH_SIZE      = 8        # Small batch due to heavy models (Swin-V2 + ConvNeXt)\n",
        "GRAD_ACCUM      = 4        # Effective batch = 32\n",
        "PHASE1_EPOCHS   = 5        # Warmup (Head only)\n",
        "PHASE2_EPOCHS   = 35       # Deep fine-tuning\n",
        "PHASE1_LR       = 1e-3\n",
        "PHASE2_LR       = 5e-5     # Lower LR for ViT stability\n",
        "WEIGHT_DECAY    = 0.05     # Higher weight decay for Transformers (AdamW standard)\n",
        "LABEL_SMOOTHING = 0.1\n",
        "MIXUP_ALPHA     = 0.2      # Beta distribution param for Mixup\n",
        "CUTMIX_ALPHA    = 1.0      # Beta distribution param for CutMix\n",
        "MIX_PROB        = 0.5      # 50% chance to apply Mixup/CutMix\n",
        "GRAD_CLIP       = 1.0      # Prevent exploding gradients\n",
        "DROP_PATH_RATE  = 0.2      # Stochastic Depth (Crucial for deep ViT/CNN)\n",
        "PATIENCE        = 8        # Early stopping patience\n",
        "NUM_WORKERS     = 0        # 0 for MPS stability\n",
        "N_FOLDS         = 5        # 5-Fold Stratified Split\n",
        "FOLD_TO_TRAIN   = 0        # Train fold 0 to keep it manageable\n",
        "\n",
        "print('‚öôÔ∏è SOTA Setup Complete!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Advanced Data Augmentation & Mixup/CutMix Engine\n",
        "SOTA pipelines rely heavily on data mixing to prevent memorization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SOTA Augmentation & Mixup Engine Ready!\n"
          ]
        }
      ],
      "source": [
        "MEAN = [0.485, 0.456, 0.406]\n",
        "STD  = [0.229, 0.224, 0.225]\n",
        "\n",
        "# ‚îÄ‚îÄ Train: Extreme Augmentation (AutoAugment style) ‚îÄ‚îÄ\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE + 32, IMG_SIZE + 32)),\n",
        "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.7, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.05),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=MEAN, std=STD),\n",
        "    transforms.RandomErasing(p=0.2, scale=(0.02, 0.15)), # Slightly milder erasing\n",
        "])\n",
        "\n",
        "# ‚îÄ‚îÄ Val: Center Crop ‚îÄ‚îÄ\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE + 32, IMG_SIZE + 32)),\n",
        "    transforms.CenterCrop(IMG_SIZE),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=MEAN, std=STD),\n",
        "])\n",
        "\n",
        "# ‚îÄ‚îÄ Custom Crop Transform (for TTA corner crops) ‚îÄ‚îÄ\n",
        "class CropTransform:\n",
        "    \"\"\"Crop a fixed region from a PIL Image.\"\"\"\n",
        "    def __init__(self, top, left, height, width):\n",
        "        self.top, self.left, self.height, self.width = top, left, height, width\n",
        "    def __call__(self, img):\n",
        "        return transforms.functional.crop(img, self.top, self.left, self.height, self.width)\n",
        "\n",
        "# ‚îÄ‚îÄ TTA (Saccadic Vision 12-Passes) ‚îÄ‚îÄ\n",
        "_SZ = IMG_SIZE; _LG = int(IMG_SIZE * 1.15)\n",
        "tta_transforms_list = [\n",
        "    # 1) Normal center crop\n",
        "    val_transforms,\n",
        "    # 2) Horizontal flip\n",
        "    transforms.Compose([transforms.Resize((_SZ,_SZ)), transforms.RandomHorizontalFlip(p=1.0), transforms.ToTensor(), transforms.Normalize(MEAN,STD)]),\n",
        "    # 3-4) Close up center crop + flipped\n",
        "    transforms.Compose([transforms.Resize((_LG,_LG)), transforms.CenterCrop(_SZ), transforms.ToTensor(), transforms.Normalize(MEAN,STD)]),\n",
        "    transforms.Compose([transforms.Resize((_LG,_LG)), transforms.CenterCrop(_SZ), transforms.RandomHorizontalFlip(p=1.0), transforms.ToTensor(), transforms.Normalize(MEAN,STD)]),\n",
        "    # 5-6) Rotations\n",
        "    transforms.Compose([transforms.Resize((_SZ,_SZ)), transforms.RandomRotation((10,10)), transforms.ToTensor(), transforms.Normalize(MEAN,STD)]),\n",
        "    transforms.Compose([transforms.Resize((_SZ,_SZ)), transforms.RandomRotation((-10,-10)), transforms.ToTensor(), transforms.Normalize(MEAN,STD)]),\n",
        "    # 7) Color shifts\n",
        "    transforms.Compose([transforms.Resize((_SZ,_SZ)), transforms.ColorJitter(brightness=0.2, contrast=0.2), transforms.ToTensor(), transforms.Normalize(MEAN,STD)]),\n",
        "    # 8-11) Corner crops (Top-Left, Top-Right, Bottom-Left, Bottom-Right)\n",
        "    transforms.Compose([transforms.Resize((_LG,_LG)), CropTransform(0, 0, _SZ, _SZ), transforms.ToTensor(), transforms.Normalize(MEAN,STD)]),\n",
        "    transforms.Compose([transforms.Resize((_LG,_LG)), CropTransform(0, _LG-_SZ, _SZ, _SZ), transforms.ToTensor(), transforms.Normalize(MEAN,STD)]),\n",
        "    transforms.Compose([transforms.Resize((_LG,_LG)), CropTransform(_LG-_SZ, 0, _SZ, _SZ), transforms.ToTensor(), transforms.Normalize(MEAN,STD)]),\n",
        "    transforms.Compose([transforms.Resize((_LG,_LG)), CropTransform(_LG-_SZ, _LG-_SZ, _SZ, _SZ), transforms.ToTensor(), transforms.Normalize(MEAN,STD)]),\n",
        "    # 12) Gaussian Blur\n",
        "    transforms.Compose([transforms.Resize((_SZ,_SZ)), transforms.GaussianBlur(3, 0.5), transforms.ToTensor(), transforms.Normalize(MEAN,STD)])\n",
        "]\n",
        "\n",
        "# ‚îÄ‚îÄ Mixup / CutMix Engine ‚îÄ‚îÄ\n",
        "def rand_bbox(size, lam):\n",
        "    \"\"\"Generate bounding box for CutMix\"\"\"\n",
        "    W, H = size[2], size[3]\n",
        "    cut_rat = np.sqrt(1. - lam)\n",
        "    cut_w = int(W * cut_rat)\n",
        "    cut_h = int(H * cut_rat)\n",
        "\n",
        "    cx = np.random.randint(W)\n",
        "    cy = np.random.randint(H)\n",
        "\n",
        "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
        "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
        "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
        "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
        "\n",
        "    return bbx1, bby1, bbx2, bby2\n",
        "\n",
        "def apply_mixup_cutmix(x, y):\n",
        "    \"\"\"Randomly apply Mixup or CutMix\"\"\"\n",
        "    mode = random.choice(['mixup', 'cutmix'])\n",
        "    alpha = MIXUP_ALPHA if mode == 'mixup' else CUTMIX_ALPHA\n",
        "    \n",
        "    lam = np.random.beta(alpha, alpha)\n",
        "    idx = torch.randperm(x.size(0)).to(x.device)\n",
        "    \n",
        "    if mode == 'mixup':\n",
        "        mixed_x = lam * x + (1 - lam) * x[idx]\n",
        "    else: # cutmix\n",
        "        bbx1, bby1, bbx2, bby2 = rand_bbox(x.size(), lam)\n",
        "        mixed_x = x.clone()\n",
        "        mixed_x[:, :, bby1:bby2, bbx1:bbx2] = x[idx, :, bby1:bby2, bbx1:bbx2]\n",
        "        # Adjust lambda to exactly match pixel ratio\n",
        "        lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (x.size()[-1] * x.size()[-2]))\n",
        "        \n",
        "    return mixed_x, y, y[idx], lam\n",
        "\n",
        "print('SOTA Augmentation & Mixup Engine Ready!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Stratified K-Fold Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classes: ['chihuahua', 'muffin'] | Total Images: 4733\n",
            "Fold 0: Train=3786 | Val=947\n"
          ]
        }
      ],
      "source": [
        "class TransformSubset(Dataset):\n",
        "    def __init__(self, dataset, indices, transform):\n",
        "        self.dataset, self.indices, self.transform = dataset, indices, transform\n",
        "    def __len__(self): return len(self.indices)\n",
        "    def __getitem__(self, idx):\n",
        "        img, label = self.dataset[self.indices[idx]]\n",
        "        if self.transform: img = self.transform(img)\n",
        "        return img, label\n",
        "\n",
        "full_dataset = datasets.ImageFolder(root=TRAIN_DIR, transform=None)\n",
        "classes      = full_dataset.classes\n",
        "class_to_idx = full_dataset.class_to_idx\n",
        "idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
        "print(f'Classes: {classes} | Total Images: {len(full_dataset)}')\n",
        "\n",
        "# Stratified 5-Fold Setup\n",
        "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
        "folds = list(skf.split(np.zeros(len(full_dataset)), full_dataset.targets))\n",
        "train_idx, val_idx = folds[FOLD_TO_TRAIN]\n",
        "\n",
        "train_dataset = TransformSubset(full_dataset, train_idx, train_transforms)\n",
        "val_dataset   = TransformSubset(full_dataset, val_idx,   val_transforms)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,  num_workers=NUM_WORKERS)\n",
        "val_loader   = DataLoader(val_dataset,   batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
        "print(f'Fold {FOLD_TO_TRAIN}: Train={len(train_dataset)} | Val={len(val_dataset)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: SOTA Hybrid Ensemble Architecture (ViT + CNN)\n",
        "- **Model A**: Swin-V2-Base (State-of-the-Art Vision Transformer)\n",
        "- **Model B**: ConvNeXt-Base (State-of-the-Art CNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ModelEMA:\n",
        "    \"\"\" Exponential Moving Average (EMA) of model weights for extreme stability. \"\"\"\n",
        "    def __init__(self, model, decay=0.999):\n",
        "        self.model = copy.deepcopy(model).eval()\n",
        "        self.decay = decay\n",
        "        for param in self.model.parameters():\n",
        "            param.requires_grad = False\n",
        "            \n",
        "    def update(self, new_model):\n",
        "        with torch.no_grad():\n",
        "            for ema_v, model_v in zip(self.model.state_dict().values(), new_model.state_dict().values()):\n",
        "                ema_v.copy_(self.decay * ema_v + (1.0 - self.decay) * model_v)\n",
        "\n",
        "def create_model(model_name='swin_v2_b', num_classes=2, freeze_backbone=True):\n",
        "    if model_name == 'swin_v2_b':\n",
        "        print(\"Loading Swin-V2-Base (ViT)...\")\n",
        "        # Pre-trained Swin-V2-Base (stochastic depth is built-in)\n",
        "        model = models.swin_v2_b(weights=models.Swin_V2_B_Weights.IMAGENET1K_V1)\n",
        "        backbone_params = list(model.features.parameters())\n",
        "        head_name = \"head\"\n",
        "        in_ft = model.head.in_features\n",
        "        model.head = nn.Linear(in_ft, num_classes)\n",
        "        \n",
        "    elif model_name == 'convnext_base':\n",
        "        print(\"Loading ConvNeXt-Base (CNN)...\")\n",
        "        model = models.convnext_base(weights=models.ConvNeXt_Base_Weights.IMAGENET1K_V1)\n",
        "        backbone_params = list(model.features.parameters())\n",
        "        head_name = \"classifier\"\n",
        "        in_ft = model.classifier[2].in_features\n",
        "        model.classifier[2] = nn.Linear(in_ft, num_classes)\n",
        "    else:\n",
        "        raise ValueError(\"Unknown model\")\n",
        "\n",
        "    if freeze_backbone:\n",
        "        for p in backbone_params:\n",
        "            p.requires_grad = False\n",
        "            \n",
        "    return model.to(device)\n",
        "\n",
        "# Provide Test Dataset class too\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, test_dir, transform=None):\n",
        "        self.test_dir, self.transform = test_dir, transform\n",
        "        self.image_files = sorted([f for f in os.listdir(test_dir) if f.lower().endswith(('.jpg','.jpeg','.png'))])\n",
        "    def __len__(self): return len(self.image_files)\n",
        "    def __getitem__(self, idx):\n",
        "        name = self.image_files[idx]\n",
        "        img  = Image.open(os.path.join(self.test_dir, name)).convert('RGB')\n",
        "        if self.transform: img = self.transform(img)\n",
        "        return img, name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Advanced Training & EMA Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_and_evaluate(model, model_name, save_path):\n",
        "    print(f\"\\n{'='*60}\\nüöÄ Starting Training Pipeline for: {model_name}\\n{'='*60}\")\n",
        "    \n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=LABEL_SMOOTHING)\n",
        "    ema_model = ModelEMA(model)\n",
        "    best_val_acc = 0.0\n",
        "    best_weights = copy.deepcopy(model.state_dict())\n",
        "    \n",
        "    # ‚îÄ‚îÄ Phase 1: Warmup Head ‚îÄ‚îÄ\n",
        "    opt1 = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=PHASE1_LR, weight_decay=WEIGHT_DECAY)\n",
        "    \n",
        "    print(\"\\n--- Phase 1: Warming up classification head ---\")\n",
        "    for ep in range(1, PHASE1_EPOCHS + 1):\n",
        "        # Train\n",
        "        model.train()\n",
        "        loss_sum, total = 0.0, 0\n",
        "        opt1.zero_grad()\n",
        "        for i, (images, labels) in enumerate(tqdm(train_loader, leave=False, desc=f\"P1 - Ep {ep}\")):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            out = model(images)\n",
        "            loss = criterion(out, labels)\n",
        "            (loss / GRAD_ACCUM).backward()\n",
        "            \n",
        "            if (i + 1) % GRAD_ACCUM == 0 or (i + 1) == len(train_loader):\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP)\n",
        "                opt1.step()\n",
        "                opt1.zero_grad()\n",
        "                ema_model.update(model) # Update EMA heavily even in P1\n",
        "            loss_sum += loss.item() * images.size(0)\n",
        "            total += images.size(0)\n",
        "            \n",
        "        # Eval (using EMA model for stability)\n",
        "        ema_model.model.eval()\n",
        "        v_loss, correct, v_total = 0.0, 0, 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                out = ema_model.model(images.to(device))\n",
        "                v_loss += criterion(out, labels.to(device)).item() * images.size(0)\n",
        "                _, preds = torch.max(out, 1)\n",
        "                correct += (preds == labels.to(device)).sum().item()\n",
        "                v_total += images.size(0)\n",
        "                \n",
        "        t_loss, v_loss, v_acc = loss_sum/total, v_loss/v_total, 100.0*correct/v_total\n",
        "        print(f\"  [Head-Only Epoch {ep}] Train Loss: {t_loss:.4f} | EMA Val Acc: {v_acc:.2f}%\")\n",
        "\n",
        "    \n",
        "    # ‚îÄ‚îÄ Phase 2: Full Backbone Fine-tuning with Mixup/CutMix ‚îÄ‚îÄ\n",
        "    # Unfreeze all\n",
        "    for p in model.parameters(): p.requires_grad = True\n",
        "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(f\"\\n--- Phase 2: Full Fine-tuning ({trainable:,} params) ---\")\n",
        "    \n",
        "    opt2 = optim.AdamW(model.parameters(), lr=PHASE2_LR, weight_decay=WEIGHT_DECAY)\n",
        "    # Cosine scheduling down to tiny LR\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(opt2, T_max=PHASE2_EPOCHS, eta_min=1e-6)\n",
        "    \n",
        "    no_improve = 0\n",
        "    for ep in range(1, PHASE2_EPOCHS + 1):\n",
        "        model.train()\n",
        "        loss_sum, total = 0.0, 0\n",
        "        opt2.zero_grad()\n",
        "        for i, (images, labels) in enumerate(tqdm(train_loader, leave=False, desc=f\"P2 - Ep {ep}\")):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            \n",
        "            # Apply Mixup/CutMix 50% of the time in Phase 2\n",
        "            if random.random() < MIX_PROB:\n",
        "                mixed, y_a, y_b, lam = apply_mixup_cutmix(images, labels)\n",
        "                out = model(mixed)\n",
        "                loss = lam * criterion(out, y_a) + (1 - lam) * criterion(out, y_b)\n",
        "            else:\n",
        "                out = model(images)\n",
        "                loss = criterion(out, labels)\n",
        "                \n",
        "            (loss / GRAD_ACCUM).backward()\n",
        "            \n",
        "            if (i + 1) % GRAD_ACCUM == 0 or (i + 1) == len(train_loader):\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP)\n",
        "                opt2.step()\n",
        "                opt2.zero_grad()\n",
        "                ema_model.update(model)\n",
        "                \n",
        "            loss_sum += loss.item() * images.size(0)\n",
        "            total += images.size(0)\n",
        "            \n",
        "        scheduler.step()\n",
        "        \n",
        "        # Eval using EMA\n",
        "        ema_model.model.eval()\n",
        "        correct, v_total = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                out = ema_model.model(images.to(device))\n",
        "                _, preds = torch.max(out, 1)\n",
        "                correct += (preds == labels.to(device)).sum().item()\n",
        "                v_total += images.size(0)\n",
        "                \n",
        "        t_loss = loss_sum / total\n",
        "        v_acc = 100.0 * correct / v_total\n",
        "        \n",
        "        flag = \" ‚≠ê BEST (Saving)\" if v_acc > best_val_acc else \"\"\n",
        "        print(f\"  [Epoch {ep:02d}/{PHASE2_EPOCHS}] Train Loss: {t_loss:.4f} | EMA Val Acc: {v_acc:.2f}% {flag}\")\n",
        "        \n",
        "        if v_acc > best_val_acc:\n",
        "            best_val_acc = v_acc\n",
        "            best_weights = copy.deepcopy(ema_model.model.state_dict())\n",
        "            torch.save(best_weights, save_path)\n",
        "            no_improve = 0\n",
        "        else:\n",
        "            no_improve += 1\n",
        "            if no_improve >= PATIENCE:\n",
        "                print(f\"üõë Early stopping triggered after {ep} epochs.\")\n",
        "                break\n",
        "                \n",
        "    # Free memory\n",
        "    del model, ema_model, opt1, opt2, criterion\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
        "    \n",
        "    return best_val_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Train Model A ‚Äî Swin-V2-Base (Vision Transformer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading Swin-V2-Base (ViT)...\n",
            "\n",
            "============================================================\n",
            "üöÄ Starting Training Pipeline for: Swin-V2-Base\n",
            "============================================================\n",
            "\n",
            "--- Phase 1: Warming up classification head ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  [Head-Only Epoch 1] Train Loss: 0.3331 | EMA Val Acc: 46.36%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  [Head-Only Epoch 2] Train Loss: 0.2452 | EMA Val Acc: 86.80%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  [Head-Only Epoch 3] Train Loss: 0.2376 | EMA Val Acc: 96.30%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  [Head-Only Epoch 4] Train Loss: 0.2345 | EMA Val Acc: 98.20%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  [Head-Only Epoch 5] Train Loss: 0.2322 | EMA Val Acc: 99.05%\n",
            "\n",
            "--- Phase 2: Full Fine-tuning (86,907,898 params) ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  [Epoch 01/35] Train Loss: 0.2812 | EMA Val Acc: 99.37%  ‚≠ê BEST (Saving)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  [Epoch 02/35] Train Loss: 0.2654 | EMA Val Acc: 99.58%  ‚≠ê BEST (Saving)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  [Epoch 03/35] Train Loss: 0.2698 | EMA Val Acc: 99.58% \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  [Epoch 04/35] Train Loss: 0.2636 | EMA Val Acc: 99.79%  ‚≠ê BEST (Saving)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  [Epoch 05/35] Train Loss: 0.2621 | EMA Val Acc: 99.79% \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  [Epoch 06/35] Train Loss: 0.2537 | EMA Val Acc: 99.79% \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  [Epoch 07/35] Train Loss: 0.2645 | EMA Val Acc: 99.79% \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  [Epoch 08/35] Train Loss: 0.2669 | EMA Val Acc: 99.79% \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  [Epoch 09/35] Train Loss: 0.2555 | EMA Val Acc: 99.79% \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                             \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  [Epoch 10/35] Train Loss: 0.2578 | EMA Val Acc: 99.79% \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                             \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  [Epoch 11/35] Train Loss: 0.2608 | EMA Val Acc: 99.79% \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                             \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  [Epoch 12/35] Train Loss: 0.2646 | EMA Val Acc: 99.79% \n",
            "üõë Early stopping triggered after 12 epochs.\n"
          ]
        }
      ],
      "source": [
        "model_a = create_model('swin_v2_b', freeze_backbone=True)\n",
        "acc_a = train_and_evaluate(model_a, 'Swin-V2-Base', 'best_swin_v2.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Train Model B ‚Äî ConvNeXt-Base (CNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading ConvNeXt-Base (CNN)...\n",
            "\n",
            "============================================================\n",
            "üöÄ Starting Training Pipeline for: ConvNeXt-Base\n",
            "============================================================\n",
            "\n",
            "--- Phase 1: Warming up classification head ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  [Head-Only Epoch 1] Train Loss: 0.2687 | EMA Val Acc: 92.29%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  [Head-Only Epoch 2] Train Loss: 0.2294 | EMA Val Acc: 97.99%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  [Head-Only Epoch 3] Train Loss: 0.2243 | EMA Val Acc: 98.94%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  [Head-Only Epoch 4] Train Loss: 0.2260 | EMA Val Acc: 99.26%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  [Head-Only Epoch 5] Train Loss: 0.2229 | EMA Val Acc: 99.37%\n",
            "\n",
            "--- Phase 2: Full Fine-tuning (87,568,514 params) ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  [Epoch 01/35] Train Loss: 0.2835 | EMA Val Acc: 99.37%  ‚≠ê BEST (Saving)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  [Epoch 02/35] Train Loss: 0.2771 | EMA Val Acc: 99.47%  ‚≠ê BEST (Saving)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  [Epoch 03/35] Train Loss: 0.2667 | EMA Val Acc: 99.47% \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  [Epoch 04/35] Train Loss: 0.2708 | EMA Val Acc: 99.47% \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  [Epoch 05/35] Train Loss: 0.2719 | EMA Val Acc: 99.58%  ‚≠ê BEST (Saving)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  [Epoch 06/35] Train Loss: 0.2650 | EMA Val Acc: 99.68%  ‚≠ê BEST (Saving)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  [Epoch 07/35] Train Loss: 0.2679 | EMA Val Acc: 99.68% \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  [Epoch 08/35] Train Loss: 0.2653 | EMA Val Acc: 99.79%  ‚≠ê BEST (Saving)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  [Epoch 09/35] Train Loss: 0.2617 | EMA Val Acc: 99.79% \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                             \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  [Epoch 10/35] Train Loss: 0.2565 | EMA Val Acc: 99.79% \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                             \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  [Epoch 11/35] Train Loss: 0.2569 | EMA Val Acc: 99.79% \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                             \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  [Epoch 12/35] Train Loss: 0.2620 | EMA Val Acc: 99.79% \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                             \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  [Epoch 13/35] Train Loss: 0.2656 | EMA Val Acc: 99.79% \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                             \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  [Epoch 14/35] Train Loss: 0.2640 | EMA Val Acc: 99.79% \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                             \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  [Epoch 15/35] Train Loss: 0.2696 | EMA Val Acc: 99.79% \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                             \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  [Epoch 16/35] Train Loss: 0.2556 | EMA Val Acc: 99.79% \n",
            "üõë Early stopping triggered after 16 epochs.\n",
            "\n",
            "üèÜ Final Single Model Accuracies -> Swin-V2: 99.79% | ConvNeXt: 99.79%\n"
          ]
        }
      ],
      "source": [
        "model_b = create_model('convnext_base', freeze_backbone=True)\n",
        "acc_b = train_and_evaluate(model_b, 'ConvNeXt-Base', 'best_convnext_sota.pth')\n",
        "\n",
        "print(f\"\\nüèÜ Final Single Model Accuracies -> Swin-V2: {acc_a:.2f}% | ConvNeXt: {acc_b:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Multi-Scale Saccadic TTA Inference (ViT + CNN Ensemble)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=========================================================\n",
            "üåç Generating Final SOTA Ensemble Predictions (2 Models √ó 12 TTA)\n",
            "=========================================================\n",
            "Loading Swin-V2-Base (ViT)...\n",
            "Loading ConvNeXt-Base (CNN)...\n",
            "  üîç TTA Pass 1/24 ([Swin-V2] Aug 1)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  üîç TTA Pass 2/24 ([Swin-V2] Aug 2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  üîç TTA Pass 3/24 ([Swin-V2] Aug 3)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  üîç TTA Pass 4/24 ([Swin-V2] Aug 4)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  üîç TTA Pass 5/24 ([Swin-V2] Aug 5)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  üîç TTA Pass 6/24 ([Swin-V2] Aug 6)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  üîç TTA Pass 7/24 ([Swin-V2] Aug 7)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  üîç TTA Pass 8/24 ([Swin-V2] Aug 8)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  üîç TTA Pass 9/24 ([Swin-V2] Aug 9)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  üîç TTA Pass 10/24 ([Swin-V2] Aug 10)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  üîç TTA Pass 11/24 ([Swin-V2] Aug 11)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  üîç TTA Pass 12/24 ([Swin-V2] Aug 12)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  üîç TTA Pass 13/24 ([ConvNeXt] Aug 1)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  üîç TTA Pass 14/24 ([ConvNeXt] Aug 2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  üîç TTA Pass 15/24 ([ConvNeXt] Aug 3)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  üîç TTA Pass 16/24 ([ConvNeXt] Aug 4)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  üîç TTA Pass 17/24 ([ConvNeXt] Aug 5)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  üîç TTA Pass 18/24 ([ConvNeXt] Aug 6)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  üîç TTA Pass 19/24 ([ConvNeXt] Aug 7)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  üîç TTA Pass 20/24 ([ConvNeXt] Aug 8)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  üîç TTA Pass 21/24 ([ConvNeXt] Aug 9)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  üîç TTA Pass 22/24 ([ConvNeXt] Aug 10)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  üîç TTA Pass 23/24 ([ConvNeXt] Aug 11)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  üîç TTA Pass 24/24 ([ConvNeXt] Aug 12)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                            "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "‚úÖ Done! High-confidence predictions generated for 1138 images.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "print('\\n=========================================================')\n",
        "print('üåç Generating Final SOTA Ensemble Predictions (2 Models √ó 12 TTA)')\n",
        "print('=========================================================')\n",
        "\n",
        "# Reload best weights\n",
        "model_a = create_model('swin_v2_b', freeze_backbone=False)\n",
        "model_a.load_state_dict(torch.load('best_swin_v2.pth', weights_only=True))\n",
        "model_a.eval()\n",
        "\n",
        "model_b = create_model('convnext_base', freeze_backbone=False)\n",
        "model_b.load_state_dict(torch.load('best_convnext_sota.pth', weights_only=True))\n",
        "model_b.eval()\n",
        "\n",
        "models_list = [model_a, model_b]\n",
        "softmax = nn.Softmax(dim=1)\n",
        "all_probs, all_filenames = None, None\n",
        "\n",
        "total_passes = len(models_list) * len(tta_transforms_list)\n",
        "pass_n = 0\n",
        "\n",
        "for m_idx, mdl in enumerate(models_list):\n",
        "    md_name = \"Swin-V2\" if m_idx == 0 else \"ConvNeXt\"\n",
        "    for t_idx, tta_tf in enumerate(tta_transforms_list):\n",
        "        pass_n += 1\n",
        "        print(f'  üîç TTA Pass {pass_n}/{total_passes} ([{md_name}] Aug {t_idx+1})')\n",
        "        td = TestDataset(TEST_DIR, transform=tta_tf)\n",
        "        tl = DataLoader(td, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
        "        \n",
        "        pass_probs, pass_files = [], []\n",
        "        with torch.no_grad():\n",
        "            for imgs, fnames in tqdm(tl, desc='Inference', leave=False):\n",
        "                p = softmax(mdl(imgs.to(device))).cpu().numpy()\n",
        "                pass_probs.append(p)\n",
        "                if t_idx == 0 and m_idx == 0: \n",
        "                    pass_files.extend(fnames)\n",
        "                    \n",
        "        pass_probs = np.concatenate(pass_probs, axis=0)\n",
        "        if all_probs is None:\n",
        "            all_probs, all_filenames = pass_probs, pass_files\n",
        "        else:\n",
        "            all_probs += pass_probs\n",
        "\n",
        "# Average the probabilities across all completely\n",
        "all_probs /= total_passes\n",
        "pred_indices = np.argmax(all_probs, axis=1)\n",
        "predictions  = [idx_to_class[i] for i in pred_indices]\n",
        "print(f'\\n‚úÖ Done! High-confidence predictions generated for {len(predictions)} images.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Save Ensembled Submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üíæ submission_sota.csv saved!\n",
            "\n",
            "Prediction distribution:\n",
            "Predict\n",
            "chihuahua    641\n",
            "muffin       497\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "40"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "submission_df = pd.DataFrame({'ID': all_filenames, 'Predict': predictions})\n",
        "submission_df.to_csv('submission_sota.csv', index=False)\n",
        "print('\\nüíæ submission_sota.csv saved!')\n",
        "print(\"\\nPrediction distribution:\")\n",
        "print(submission_df['Predict'].value_counts())\n",
        "\n",
        "# Cleanup huge models from RAM\n",
        "del model_a, model_b\n",
        "gc.collect()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
