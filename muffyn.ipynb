{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Import Libraries & Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using Apple MPS (GPU) üöÄ\n",
            "TRAIN_DIR exists: True\n",
            "TEST_DIR  exists: True\n",
            "Setup complete!\n"
          ]
        }
      ],
      "source": [
        "import ssl\n",
        "ssl._create_default_https_context = ssl._create_unverified_context\n",
        "\n",
        "import os, copy, random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, datasets, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available(): torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "if torch.backends.mps.is_available():\n",
        "    device = torch.device('mps'); print('Using Apple MPS (GPU) üöÄ')\n",
        "elif torch.cuda.is_available():\n",
        "    device = torch.device('cuda'); print(f'Using CUDA: {torch.cuda.get_device_name(0)}')\n",
        "else:\n",
        "    device = torch.device('cpu'); print('Using CPU')\n",
        "\n",
        "if os.path.exists('/kaggle/input'):\n",
        "    BASE_DIR = '/kaggle/input/cs-460-muffin-vs-chihuahua-classification-challenge'\n",
        "else:\n",
        "    BASE_DIR = './data'\n",
        "TRAIN_DIR = f'{BASE_DIR}/train'\n",
        "TEST_DIR  = f'{BASE_DIR}/kaggle_test_final'\n",
        "print(f'TRAIN_DIR exists: {os.path.exists(TRAIN_DIR)}')\n",
        "print(f'TEST_DIR  exists: {os.path.exists(TEST_DIR)}')\n",
        "\n",
        "IMG_SIZE        = 320\n",
        "BATCH_SIZE      = 12\n",
        "PHASE1_EPOCHS   = 5\n",
        "PHASE2_EPOCHS   = 30\n",
        "PHASE1_LR       = 1e-3\n",
        "PHASE2_LR       = 2e-4\n",
        "VAL_SPLIT       = 0.15\n",
        "PATIENCE        = 8\n",
        "MIXUP_ALPHA     = 0.2\n",
        "LABEL_SMOOTHING = 0.1\n",
        "WEIGHT_DECAY    = 1e-4\n",
        "GRAD_CLIP       = 1.0\n",
        "GRAD_ACCUM      = 2\n",
        "NUM_WORKERS     = 0\n",
        "print('Setup complete!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Data Transforms + Mixup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transforms ready! TTA passes: 8\n"
          ]
        }
      ],
      "source": [
        "MEAN = [0.485, 0.456, 0.406]\n",
        "STD  = [0.229, 0.224, 0.225]\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE + 40, IMG_SIZE + 40)),\n",
        "    transforms.RandomCrop(IMG_SIZE),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.05),\n",
        "    transforms.RandomRotation(25),\n",
        "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.05),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.05, 0.05), scale=(0.95, 1.05)),\n",
        "    transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 1.0)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=MEAN, std=STD),\n",
        "    transforms.RandomErasing(p=0.25, scale=(0.02, 0.2)),\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=MEAN, std=STD),\n",
        "])\n",
        "\n",
        "_SZ = IMG_SIZE; _LG = int(IMG_SIZE * 1.15)\n",
        "tta_transforms_list = [\n",
        "    transforms.Compose([transforms.Resize((_SZ,_SZ)), transforms.ToTensor(), transforms.Normalize(MEAN,STD)]),\n",
        "    transforms.Compose([transforms.Resize((_SZ,_SZ)), transforms.RandomHorizontalFlip(p=1.0), transforms.ToTensor(), transforms.Normalize(MEAN,STD)]),\n",
        "    transforms.Compose([transforms.Resize((_LG,_LG)), transforms.CenterCrop(_SZ), transforms.ToTensor(), transforms.Normalize(MEAN,STD)]),\n",
        "    transforms.Compose([transforms.Resize((_SZ,_SZ)), transforms.RandomRotation((15,15)), transforms.ToTensor(), transforms.Normalize(MEAN,STD)]),\n",
        "    transforms.Compose([transforms.Resize((_SZ,_SZ)), transforms.RandomRotation((-15,-15)), transforms.ToTensor(), transforms.Normalize(MEAN,STD)]),\n",
        "    transforms.Compose([transforms.Resize((_SZ,_SZ)), transforms.ColorJitter(brightness=0.2, contrast=0.2), transforms.ToTensor(), transforms.Normalize(MEAN,STD)]),\n",
        "    transforms.Compose([transforms.Resize((_SZ,_SZ)), transforms.RandomHorizontalFlip(p=1.0), transforms.RandomRotation((10,10)), transforms.ToTensor(), transforms.Normalize(MEAN,STD)]),\n",
        "    transforms.Compose([transforms.Resize((_LG,_LG)), transforms.CenterCrop(_SZ), transforms.RandomHorizontalFlip(p=1.0), transforms.ToTensor(), transforms.Normalize(MEAN,STD)]),\n",
        "]\n",
        "\n",
        "def mixup_data(x, y, alpha=0.2):\n",
        "    lam = np.random.beta(alpha, alpha) if alpha > 0 else 1.0\n",
        "    idx = torch.randperm(x.size(0)).to(x.device)\n",
        "    return lam * x + (1 - lam) * x[idx], y, y[idx], lam\n",
        "\n",
        "print(f'Transforms ready! TTA passes: {len(tta_transforms_list)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Load Dataset & Stratified Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classes: ['chihuahua', 'muffin'] | class_to_idx: {'chihuahua': 0, 'muffin': 1} | Total: 4733\n",
            "Train: 4023 | Val: 710\n"
          ]
        }
      ],
      "source": [
        "class TransformSubset(Dataset):\n",
        "    def __init__(self, dataset, indices, transform):\n",
        "        self.dataset, self.indices, self.transform = dataset, indices, transform\n",
        "    def __len__(self): return len(self.indices)\n",
        "    def __getitem__(self, idx):\n",
        "        img, label = self.dataset[self.indices[idx]]\n",
        "        if self.transform: img = self.transform(img)\n",
        "        return img, label\n",
        "\n",
        "full_dataset = datasets.ImageFolder(root=TRAIN_DIR, transform=None)\n",
        "classes      = full_dataset.classes\n",
        "class_to_idx = full_dataset.class_to_idx\n",
        "idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
        "print(f'Classes: {classes} | class_to_idx: {class_to_idx} | Total: {len(full_dataset)}')\n",
        "\n",
        "train_idx, val_idx = train_test_split(\n",
        "    list(range(len(full_dataset))), test_size=VAL_SPLIT,\n",
        "    stratify=full_dataset.targets, random_state=SEED)\n",
        "\n",
        "train_dataset = TransformSubset(full_dataset, train_idx, train_transforms)\n",
        "val_dataset   = TransformSubset(full_dataset, val_idx,   val_transforms)\n",
        "train_loader  = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,  num_workers=NUM_WORKERS)\n",
        "val_loader    = DataLoader(val_dataset,   batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
        "print(f'Train: {len(train_dataset)} | Val: {len(val_dataset)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test images: 1138\n"
          ]
        }
      ],
      "source": [
        "class TestDataset(Dataset):\n",
        "    def __init__(self, test_dir, transform=None):\n",
        "        self.test_dir, self.transform = test_dir, transform\n",
        "        self.image_files = sorted([f for f in os.listdir(test_dir) if f.lower().endswith(('.jpg','.jpeg','.png'))])\n",
        "    def __len__(self): return len(self.image_files)\n",
        "    def __getitem__(self, idx):\n",
        "        name = self.image_files[idx]\n",
        "        img  = Image.open(os.path.join(self.test_dir, name)).convert('RGB')\n",
        "        if self.transform: img = self.transform(img)\n",
        "        return img, name\n",
        "\n",
        "print(f'Test images: {len(TestDataset(TEST_DIR))}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Build Model ‚Äî ConvNeXt-Base\n",
        "ConvNeXt-Base (~89M params) ‡πÉ‡∏ä‡πâ‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î Transformer ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á CNN\n",
        "‡∏°‡∏µ Global Receptive Field ‡∏Å‡∏ß‡πâ‡∏≤‡∏á + ‡πÅ‡∏¢‡∏Å‡πÅ‡∏¢‡∏∞ texture ‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÑ‡∏î‡πâ‡∏î‡∏µ‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/convnext_base-6075fbad.pth\" to /Users/linkalphx/.cache/torch/hub/checkpoints/convnext_base-6075fbad.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 338M/338M [00:47<00:00, 7.40MB/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ConvNeXt-Base ready! Trainable: 4,098 / 87,568,514\n"
          ]
        }
      ],
      "source": [
        "model = models.convnext_base(weights=models.ConvNeXt_Base_Weights.IMAGENET1K_V1)\n",
        "\n",
        "# Freeze backbone\n",
        "for p in model.features.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "# Replace classifier head for 2 classes\n",
        "in_ft = model.classifier[2].in_features\n",
        "model.classifier[2] = nn.Linear(in_ft, 2)\n",
        "model = model.to(device)\n",
        "\n",
        "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "total_p   = sum(p.numel() for p in model.parameters())\n",
        "print(f'ConvNeXt-Base ready! Trainable: {trainable:,} / {total_p:,}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Training & Evaluation Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training functions ready!\n"
          ]
        }
      ],
      "source": [
        "def train_one_epoch(model, loader, criterion, optimizer, use_mixup=False, alpha=0.2, grad_accum=1):\n",
        "    model.train()\n",
        "    loss_sum, correct, total = 0.0, 0, 0\n",
        "    optimizer.zero_grad()\n",
        "    for i, (images, labels) in enumerate(tqdm(loader, leave=False)):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        if use_mixup:\n",
        "            mixed, y_a, y_b, lam = mixup_data(images, labels, alpha)\n",
        "            out  = model(mixed)\n",
        "            loss = lam * criterion(out, y_a) + (1 - lam) * criterion(out, y_b)\n",
        "        else:\n",
        "            out  = model(images)\n",
        "            loss = criterion(out, labels)\n",
        "        (loss / grad_accum).backward()\n",
        "        if (i + 1) % grad_accum == 0 or (i + 1) == len(loader):\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP)\n",
        "            optimizer.step(); optimizer.zero_grad()\n",
        "        loss_sum += loss.item()\n",
        "        _, preds = torch.max(out, 1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total   += labels.size(0)\n",
        "    return loss_sum / len(loader), 100.0 * correct / total\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader, criterion):\n",
        "    model.eval()\n",
        "    loss_sum, correct, total = 0.0, 0, 0\n",
        "    for images, labels in loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        out = model(images); loss = criterion(out, labels)\n",
        "        loss_sum += loss.item()\n",
        "        _, preds = torch.max(out, 1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total   += labels.size(0)\n",
        "    return loss_sum / len(loader), 100.0 * correct / total\n",
        "\n",
        "print('Training functions ready!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Phase 1 ‚Äî Train Head Only (LR=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===== Phase 1: Head Only =====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [01/5] Train Loss: 0.2452 Acc: 98.51% | Val Loss: 0.2225 Acc: 99.58% ‚òÖ BEST\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [02/5] Train Loss: 0.2281 Acc: 99.43% | Val Loss: 0.2217 Acc: 99.30%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [03/5] Train Loss: 0.2227 Acc: 99.50% | Val Loss: 0.2201 Acc: 99.58%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                   \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [04/5] Train Loss: 0.2203 Acc: 99.68% | Val Loss: 0.2186 Acc: 99.44%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [05/5] Train Loss: 0.2199 Acc: 99.68% | Val Loss: 0.2188 Acc: 99.58%\n",
            "\n",
            "Best Val Accuracy (Phase 1): 99.58%\n"
          ]
        }
      ],
      "source": [
        "criterion    = nn.CrossEntropyLoss(label_smoothing=LABEL_SMOOTHING)\n",
        "best_val_acc = 0.0\n",
        "best_weights = copy.deepcopy(model.state_dict())\n",
        "\n",
        "opt1 = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=PHASE1_LR, weight_decay=WEIGHT_DECAY)\n",
        "sch1 = optim.lr_scheduler.CosineAnnealingLR(opt1, T_max=PHASE1_EPOCHS, eta_min=1e-6)\n",
        "\n",
        "print('===== Phase 1: Head Only =====')\n",
        "for ep in range(1, PHASE1_EPOCHS + 1):\n",
        "    tl, ta = train_one_epoch(model, train_loader, criterion, opt1, use_mixup=False, grad_accum=1)\n",
        "    vl, va = evaluate(model, val_loader, criterion)\n",
        "    sch1.step()\n",
        "    flag = ' ‚òÖ BEST' if va > best_val_acc else ''\n",
        "    print(f'Epoch [{ep:02d}/{PHASE1_EPOCHS}] Train Loss: {tl:.4f} Acc: {ta:.2f}% | Val Loss: {vl:.4f} Acc: {va:.2f}%{flag}')\n",
        "    if va > best_val_acc:\n",
        "        best_val_acc = va; best_weights = copy.deepcopy(model.state_dict())\n",
        "        torch.save(best_weights, 'best_model.pth')\n",
        "print(f'\\nBest Val Accuracy (Phase 1): {best_val_acc:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Phase 2 ‚Äî Full Fine-tune with Mixup (LR=2e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Phase 2 Trainable params: 87,568,514\n",
            "\n",
            "===== Phase 2: Full Fine-tune + Mixup =====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                  \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [01/30] Train Loss: 0.3022 Acc: 75.62% | Val Loss: 0.2032 Acc: 99.72% ‚òÖ BEST\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [02/30] Train Loss: 0.2981 Acc: 75.66% | Val Loss: 0.2139 Acc: 99.86% ‚òÖ BEST\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [03/30] Train Loss: 0.2996 Acc: 77.11% | Val Loss: 0.2041 Acc: 99.86%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [04/30] Train Loss: 0.2887 Acc: 77.78% | Val Loss: 0.2034 Acc: 100.00% ‚òÖ BEST\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [05/30] Train Loss: 0.2930 Acc: 79.27% | Val Loss: 0.2049 Acc: 99.58%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [06/30] Train Loss: 0.2823 Acc: 79.12% | Val Loss: 0.2062 Acc: 99.72%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [07/30] Train Loss: 0.2910 Acc: 75.71% | Val Loss: 0.2027 Acc: 99.72%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [08/30] Train Loss: 0.2834 Acc: 76.31% | Val Loss: 0.2005 Acc: 99.86%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [09/30] Train Loss: 0.2776 Acc: 77.13% | Val Loss: 0.2073 Acc: 99.86%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [10/30] Train Loss: 0.2772 Acc: 78.70% | Val Loss: 0.2035 Acc: 99.72%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [11/30] Train Loss: 0.2802 Acc: 76.01% | Val Loss: 0.2048 Acc: 99.72%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [12/30] Train Loss: 0.2697 Acc: 77.93% | Val Loss: 0.2066 Acc: 99.72%\n",
            "Early stopping at epoch 12\n",
            "\n",
            "Final Best Val Accuracy: 100.00%\n"
          ]
        }
      ],
      "source": [
        "model.load_state_dict(best_weights)\n",
        "for p in model.parameters(): p.requires_grad = True\n",
        "\n",
        "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'Phase 2 Trainable params: {trainable:,}')\n",
        "\n",
        "opt2 = optim.AdamW(model.parameters(), lr=PHASE2_LR, weight_decay=WEIGHT_DECAY)\n",
        "sch2 = optim.lr_scheduler.CosineAnnealingLR(opt2, T_max=PHASE2_EPOCHS, eta_min=1e-6)\n",
        "no_improve = 0\n",
        "\n",
        "print('\\n===== Phase 2: Full Fine-tune + Mixup =====')\n",
        "for ep in range(1, PHASE2_EPOCHS + 1):\n",
        "    tl, ta = train_one_epoch(model, train_loader, criterion, opt2,\n",
        "                             use_mixup=True, alpha=MIXUP_ALPHA, grad_accum=GRAD_ACCUM)\n",
        "    vl, va = evaluate(model, val_loader, criterion)\n",
        "    sch2.step()\n",
        "    flag = ' ‚òÖ BEST' if va > best_val_acc else ''\n",
        "    print(f'Epoch [{ep:02d}/{PHASE2_EPOCHS}] Train Loss: {tl:.4f} Acc: {ta:.2f}% | Val Loss: {vl:.4f} Acc: {va:.2f}%{flag}')\n",
        "    if va > best_val_acc:\n",
        "        best_val_acc = va; best_weights = copy.deepcopy(model.state_dict())\n",
        "        torch.save(best_weights, 'best_model.pth'); no_improve = 0\n",
        "    else:\n",
        "        no_improve += 1\n",
        "        if no_improve >= PATIENCE:\n",
        "            print(f'Early stopping at epoch {ep}'); break\n",
        "\n",
        "model.load_state_dict(best_weights)\n",
        "print(f'\\nFinal Best Val Accuracy: {best_val_acc:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: TTA Inference on Test Set (8 passes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting TTA Inference...\n",
            "  TTA pass 1/8...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                      \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  TTA pass 2/8...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                      \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  TTA pass 3/8...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                      \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  TTA pass 4/8...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                      \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  TTA pass 5/8...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                      \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  TTA pass 6/8...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                      \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  TTA pass 7/8...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                      \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  TTA pass 8/8...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                      "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done! Total predictions: 1138\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "print('Starting TTA Inference...')\n",
        "model.eval()\n",
        "softmax = nn.Softmax(dim=1)\n",
        "all_probs, all_filenames = None, None\n",
        "\n",
        "for t_idx, tta_tf in enumerate(tta_transforms_list):\n",
        "    print(f'  TTA pass {t_idx+1}/{len(tta_transforms_list)}...')\n",
        "    td = TestDataset(TEST_DIR, transform=tta_tf)\n",
        "    tl = DataLoader(td, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
        "    pass_probs, pass_files = [], []\n",
        "    with torch.no_grad():\n",
        "        for imgs, fnames in tqdm(tl, desc=f'TTA {t_idx+1}', leave=False):\n",
        "            p = softmax(model(imgs.to(device))).cpu().numpy()\n",
        "            pass_probs.append(p)\n",
        "            if t_idx == 0: pass_files.extend(fnames)\n",
        "    pass_probs = np.concatenate(pass_probs, axis=0)\n",
        "    if all_probs is None:\n",
        "        all_probs, all_filenames = pass_probs, pass_files\n",
        "    else:\n",
        "        all_probs += pass_probs\n",
        "\n",
        "all_probs   /= len(tta_transforms_list)\n",
        "pred_indices = np.argmax(all_probs, axis=1)\n",
        "predictions  = [idx_to_class[i] for i in pred_indices]\n",
        "print(f'Done! Total predictions: {len(predictions)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 10: Save submission.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "submission.csv saved!\n",
            "               ID    Predict\n",
            "0     img_0_0.jpg     muffin\n",
            "1    img_0_10.jpg     muffin\n",
            "2  img_0_1000.jpg     muffin\n",
            "3  img_0_1037.jpg     muffin\n",
            "4   img_0_105.jpg     muffin\n",
            "5  img_0_1050.jpg     muffin\n",
            "6  img_0_1051.jpg     muffin\n",
            "7  img_0_1061.jpg     muffin\n",
            "8  img_0_1063.jpg     muffin\n",
            "9  img_0_1071.jpg  chihuahua\n",
            "\n",
            "Prediction distribution:\n",
            "Predict\n",
            "chihuahua    642\n",
            "muffin       496\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "submission_df = pd.DataFrame({'ID': all_filenames, 'Predict': predictions})\n",
        "submission_df.to_csv('submission.csv', index=False)\n",
        "print('submission.csv saved!')\n",
        "print(submission_df.head(10))\n",
        "print(f'\\nPrediction distribution:')\n",
        "print(submission_df['Predict'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 11: Confusion Matrix & Classification Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Classification Report (Validation Set) ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   chihuahua       1.00      1.00      1.00       384\n",
            "      muffin       1.00      1.00      1.00       326\n",
            "\n",
            "    accuracy                           1.00       710\n",
            "   macro avg       1.00      1.00      1.00       710\n",
            "weighted avg       1.00      1.00      1.00       710\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "model.eval()\n",
        "y_true, y_pred_all = [], []\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_loader:\n",
        "        outputs  = model(images.to(device))\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "        y_pred_all.extend(preds.cpu().numpy())\n",
        "\n",
        "print('--- Classification Report (Validation Set) ---')\n",
        "print(classification_report(y_true, y_pred_all, target_names=classes))\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred_all)\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
        "plt.title(f'Confusion Matrix ‚Äî Val Acc: {best_val_acc:.2f}%')\n",
        "plt.xlabel('Predicted'); plt.ylabel('True')\n",
        "plt.tight_layout(); plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
